{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For some reason, there are broken table tags in a lot of the tables below when they're rendered on Github. They don't actually look like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216930, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('data/JEOPARDY_CSV.csv', encoding='utf-8')\n",
    "full_df = pd.read_csv('../data/JEOPARDY_CSV.csv', encoding='utf-8')\n",
    "print full_df.shape\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = full_df.sample(frac=0.01)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4666</td>\n",
       "      <td>2004-12-13</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>DON WE NOW OUR GUY APPAREL</td>\n",
       "      <td>$200</td>\n",
       "      <td>The 2 numbers on a man's dress shirt, 16/34 fo...</td>\n",
       "      <td>neck size and sleeve length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5549</td>\n",
       "      <td>2008-10-23</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>VERBS</td>\n",
       "      <td>$1000</td>\n",
       "      <td>This verb means to use another's work without ...</td>\n",
       "      <td>to pirate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6238</td>\n",
       "      <td>2011-11-02</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PAY BALL!</td>\n",
       "      <td>$600</td>\n",
       "      <td>This player nicknamed \"Big Papi\" pulls down $1...</td>\n",
       "      <td>David Ortiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4657</td>\n",
       "      <td>2004-11-30</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>FUNNY HATS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>In Wagner's operas, this eldest Valkyrie is st...</td>\n",
       "      <td>Brunhilde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2873</td>\n",
       "      <td>1997-02-12</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>WOMEN AUTHORS</td>\n",
       "      <td>$200</td>\n",
       "      <td>Kim Wozencraft &amp; Dorothy Uhnak used their expe...</td>\n",
       "      <td>Policewomen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date             Round                    Category  \\\n",
       "0         4666  2004-12-13         Jeopardy!  DON WE NOW OUR GUY APPAREL   \n",
       "1         5549  2008-10-23         Jeopardy!                       VERBS   \n",
       "2         6238  2011-11-02         Jeopardy!                   PAY BALL!   \n",
       "3         4657  2004-11-30  Double Jeopardy!                  FUNNY HATS   \n",
       "4         2873  1997-02-12         Jeopardy!               WOMEN AUTHORS   \n",
       "\n",
       "   Value                                           Question  \\\n",
       "0   $200  The 2 numbers on a man's dress shirt, 16/34 fo...   \n",
       "1  $1000  This verb means to use another's work without ...   \n",
       "2   $600  This player nicknamed \"Big Papi\" pulls down $1...   \n",
       "3  $2000  In Wagner's operas, this eldest Valkyrie is st...   \n",
       "4   $200  Kim Wozencraft & Dorothy Uhnak used their expe...   \n",
       "\n",
       "                        Answer  \n",
       "0  neck size and sleeve length  \n",
       "1                    to pirate  \n",
       "2                  David Ortiz  \n",
       "3                    Brunhilde  \n",
       "4                  Policewomen  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4666</td>\n",
       "      <td>2004-12-13</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>DON WE NOW OUR GUY APPAREL</td>\n",
       "      <td>200.0</td>\n",
       "      <td>The 2 numbers on a man's dress shirt, 16/34 fo...</td>\n",
       "      <td>neck size and sleeve length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5549</td>\n",
       "      <td>2008-10-23</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>VERBS</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>This verb means to use another's work without ...</td>\n",
       "      <td>to pirate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6238</td>\n",
       "      <td>2011-11-02</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PAY BALL!</td>\n",
       "      <td>600.0</td>\n",
       "      <td>This player nicknamed \"Big Papi\" pulls down $1...</td>\n",
       "      <td>David Ortiz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4657</td>\n",
       "      <td>2004-11-30</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>FUNNY HATS</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>In Wagner's operas, this eldest Valkyrie is st...</td>\n",
       "      <td>Brunhilde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2873</td>\n",
       "      <td>1997-02-12</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>WOMEN AUTHORS</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Kim Wozencraft &amp; Dorothy Uhnak used their expe...</td>\n",
       "      <td>Policewomen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date             Round                    Category  \\\n",
       "0         4666 2004-12-13         Jeopardy!  DON WE NOW OUR GUY APPAREL   \n",
       "1         5549 2008-10-23         Jeopardy!                       VERBS   \n",
       "2         6238 2011-11-02         Jeopardy!                   PAY BALL!   \n",
       "3         4657 2004-11-30  Double Jeopardy!                  FUNNY HATS   \n",
       "4         2873 1997-02-12         Jeopardy!               WOMEN AUTHORS   \n",
       "\n",
       "    Value                                           Question  \\\n",
       "0   200.0  The 2 numbers on a man's dress shirt, 16/34 fo...   \n",
       "1  1000.0  This verb means to use another's work without ...   \n",
       "2   600.0  This player nicknamed \"Big Papi\" pulls down $1...   \n",
       "3  2000.0  In Wagner's operas, this eldest Valkyrie is st...   \n",
       "4   200.0  Kim Wozencraft & Dorothy Uhnak used their expe...   \n",
       "\n",
       "                        Answer  \n",
       "0  neck size and sleeve length  \n",
       "1                    to pirate  \n",
       "2                  David Ortiz  \n",
       "3                    Brunhilde  \n",
       "4                  Policewomen  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the dumb spaces\n",
    "df.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']\n",
    "\n",
    "# Convert to Datetime\n",
    "df['Air Date'] = pd.to_datetime(df['Air Date'])\n",
    "\n",
    "# Clean out Value column\n",
    "df['Value'] = df['Value'].str.replace('$','')\n",
    "df['Value'] = df['Value'].str.replace(',','')\n",
    "df['Value'] = df['Value'].apply(lambda x: None if x == 'None' else int(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "He explained his \"Decision Points\" in the 2010 book of that name                                                 1\n",
       "As a boy in Kansas, he said his dream was to be a Major League Baseball player; he went into the Army instead    1\n",
       "Remixes from her \"Post\" album are featured on this Icelandic pop star's 1996 album \"Telegram\"                    1\n",
       "The name of this third male human to be mentioned in Genesis means \"breath\" in Hebrew                            1\n",
       "Gentile da Fabriano used the international Gothic style for his painting \"The Adoration Of\" this trio            1\n",
       "Name: Question, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Question'].value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2169, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop some useless questions\n",
    "df = df[df['Question'] != '[audio clue]']\n",
    "df = df[df['Question'] != '[video clue]']\n",
    "df = df[df['Question'] != '[filler]']\n",
    "df = df[df['Question'] != '(audio clue)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2168, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your']\n"
     ]
    }
   ],
   "source": [
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print len(stopwords)\n",
    "print stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_clean_columns(df):    \n",
    "    df['clean_question'] = df['Question'].apply(cleanhtml)\n",
    "    df['clean_answer'] = df['Answer'].apply(cleanhtml)\n",
    "    df['clean_category'] = df['Category'].apply(cleanhtml)\n",
    "    df['everything'] = df['clean_question']+' '+df['clean_answer']+' '+df['clean_category']\n",
    "    return df\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    cleantext = cleantext.replace('\\n', '')\n",
    "#     cleantext = cleantext.translate(None, string.punctuation)\n",
    "#     cleantext = cleantext.replace('\\'', '')\n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    cleantext = regex.sub('', cleantext)\n",
    "    cleantext = cleantext.lower()\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "      <th>clean_category</th>\n",
       "      <th>everything</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4666</td>\n",
       "      <td>2004-12-13</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>DON WE NOW OUR GUY APPAREL</td>\n",
       "      <td>200.0</td>\n",
       "      <td>The 2 numbers on a man's dress shirt, 16/34 fo...</td>\n",
       "      <td>neck size and sleeve length</td>\n",
       "      <td>the 2 numbers on a mans dress shirt 1634 for e...</td>\n",
       "      <td>neck size and sleeve length</td>\n",
       "      <td>don we now our guy apparel</td>\n",
       "      <td>the 2 numbers on a mans dress shirt 1634 for e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5549</td>\n",
       "      <td>2008-10-23</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>VERBS</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>This verb means to use another's work without ...</td>\n",
       "      <td>to pirate</td>\n",
       "      <td>this verb means to use anothers work without p...</td>\n",
       "      <td>to pirate</td>\n",
       "      <td>verbs</td>\n",
       "      <td>this verb means to use anothers work without p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6238</td>\n",
       "      <td>2011-11-02</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PAY BALL!</td>\n",
       "      <td>600.0</td>\n",
       "      <td>This player nicknamed \"Big Papi\" pulls down $1...</td>\n",
       "      <td>David Ortiz</td>\n",
       "      <td>this player nicknamed big papi pulls down 125 ...</td>\n",
       "      <td>david ortiz</td>\n",
       "      <td>pay ball</td>\n",
       "      <td>this player nicknamed big papi pulls down 125 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4657</td>\n",
       "      <td>2004-11-30</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>FUNNY HATS</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>In Wagner's operas, this eldest Valkyrie is st...</td>\n",
       "      <td>Brunhilde</td>\n",
       "      <td>in wagners operas this eldest valkyrie is ster...</td>\n",
       "      <td>brunhilde</td>\n",
       "      <td>funny hats</td>\n",
       "      <td>in wagners operas this eldest valkyrie is ster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2873</td>\n",
       "      <td>1997-02-12</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>WOMEN AUTHORS</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Kim Wozencraft &amp; Dorothy Uhnak used their expe...</td>\n",
       "      <td>Policewomen</td>\n",
       "      <td>kim wozencraft  dorothy uhnak used their exper...</td>\n",
       "      <td>policewomen</td>\n",
       "      <td>women authors</td>\n",
       "      <td>kim wozencraft  dorothy uhnak used their exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>968</td>\n",
       "      <td>1988-11-16</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>FAMOUS WOMEN</td>\n",
       "      <td>400.0</td>\n",
       "      <td>In 1955 this miniskirt innovator opened her fi...</td>\n",
       "      <td>Mary Quant</td>\n",
       "      <td>in 1955 this miniskirt innovator opened her fi...</td>\n",
       "      <td>mary quant</td>\n",
       "      <td>famous women</td>\n",
       "      <td>in 1955 this miniskirt innovator opened her fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4646</td>\n",
       "      <td>2004-11-15</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HORNED ANIMALS</td>\n",
       "      <td>800.0</td>\n",
       "      <td>This North American animal's population had dr...</td>\n",
       "      <td>the buffalo (or the bison)</td>\n",
       "      <td>this north american animals population had dro...</td>\n",
       "      <td>the buffalo or the bison</td>\n",
       "      <td>horned animals</td>\n",
       "      <td>this north american animals population had dro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4031</td>\n",
       "      <td>2002-02-25</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>BEHIND THE MUSIC</td>\n",
       "      <td>800.0</td>\n",
       "      <td>&lt;a href=\"http://www.j-archive.com/media/2002-0...</td>\n",
       "      <td>Grease</td>\n",
       "      <td>this 50s high school love story thats thrilled...</td>\n",
       "      <td>grease</td>\n",
       "      <td>behind the music</td>\n",
       "      <td>this 50s high school love story thats thrilled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4455</td>\n",
       "      <td>2004-01-09</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>RITE ON!</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Among the 5 pillars of this religion is Salat,...</td>\n",
       "      <td>Islam</td>\n",
       "      <td>among the 5 pillars of this religion is salat ...</td>\n",
       "      <td>islam</td>\n",
       "      <td>rite on</td>\n",
       "      <td>among the 5 pillars of this religion is salat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3019</td>\n",
       "      <td>1997-10-16</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>STRAIT TALK</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>On July 3, 1988 an Iranian airliner enroute to...</td>\n",
       "      <td>the Strait of Hormuz</td>\n",
       "      <td>on july 3 1988 an iranian airliner enroute to ...</td>\n",
       "      <td>the strait of hormuz</td>\n",
       "      <td>strait talk</td>\n",
       "      <td>on july 3 1988 an iranian airliner enroute to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5468</td>\n",
       "      <td>2008-05-21</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>POTPOURRI</td>\n",
       "      <td>200.0</td>\n",
       "      <td>A special flower for April, it can be oxeye or...</td>\n",
       "      <td>a daisy</td>\n",
       "      <td>a special flower for april it can be oxeye or ...</td>\n",
       "      <td>a daisy</td>\n",
       "      <td>potpourri</td>\n",
       "      <td>a special flower for april it can be oxeye or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4684</td>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>NOW THAT'S INVENTIVE!</td>\n",
       "      <td>200.0</td>\n",
       "      <td>In 1889 this Elizabethport, New Jersey company...</td>\n",
       "      <td>Singer</td>\n",
       "      <td>in 1889 this elizabethport new jersey company ...</td>\n",
       "      <td>singer</td>\n",
       "      <td>now thats inventive</td>\n",
       "      <td>in 1889 this elizabethport new jersey company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4538</td>\n",
       "      <td>2004-05-05</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>CHARACTERS IN BOOKS</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>With a little imagination &amp; his purple crayon,...</td>\n",
       "      <td>Harold</td>\n",
       "      <td>with a little imagination  his purple crayon h...</td>\n",
       "      <td>harold</td>\n",
       "      <td>characters in books</td>\n",
       "      <td>with a little imagination  his purple crayon h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3014</td>\n",
       "      <td>1997-10-09</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>TV TWINS</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Name shared by Phoebe's twin (also played by L...</td>\n",
       "      <td>Ursula</td>\n",
       "      <td>name shared by phoebes twin also played by lis...</td>\n",
       "      <td>ursula</td>\n",
       "      <td>tv twins</td>\n",
       "      <td>name shared by phoebes twin also played by lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3637</td>\n",
       "      <td>2000-05-30</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>\"HOTEL\"s</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Greta Garbo &amp; John Barrymore are 2 of the gues...</td>\n",
       "      <td>Grand Hotel</td>\n",
       "      <td>greta garbo  john barrymore are 2 of the guest...</td>\n",
       "      <td>grand hotel</td>\n",
       "      <td>hotels</td>\n",
       "      <td>greta garbo  john barrymore are 2 of the guest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5122</td>\n",
       "      <td>2006-12-12</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>CHURCHES &amp; CATHEDRALS</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>In Ulm, Germany the tallest spire in the world...</td>\n",
       "      <td>gothic</td>\n",
       "      <td>in ulm germany the tallest spire in the world ...</td>\n",
       "      <td>gothic</td>\n",
       "      <td>churches  cathedrals</td>\n",
       "      <td>in ulm germany the tallest spire in the world ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3495</td>\n",
       "      <td>1999-11-12</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>STORY PROBLEMS</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Hank's mobile home is this long, 1 3/4 times l...</td>\n",
       "      <td>14 feet</td>\n",
       "      <td>hanks mobile home is this long 1 34 times long...</td>\n",
       "      <td>14 feet</td>\n",
       "      <td>story problems</td>\n",
       "      <td>hanks mobile home is this long 1 34 times long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5600</td>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>\"F\" I DO SAY SO</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>This compound word is a forward artillery posi...</td>\n",
       "      <td>a firebase</td>\n",
       "      <td>this compound word is a forward artillery posi...</td>\n",
       "      <td>a firebase</td>\n",
       "      <td>f i do say so</td>\n",
       "      <td>this compound word is a forward artillery posi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4255</td>\n",
       "      <td>2003-02-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>NECCO SWEETHEARTS</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2-letter word that precedes \"mine\", \"good\" &amp; \"...</td>\n",
       "      <td>be</td>\n",
       "      <td>2letter word that precedes mine good  true on ...</td>\n",
       "      <td>be</td>\n",
       "      <td>necco sweethearts</td>\n",
       "      <td>2letter word that precedes mine good  true on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4542</td>\n",
       "      <td>2004-05-11</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>N\"AA\"CP</td>\n",
       "      <td>400.0</td>\n",
       "      <td>The professor who created this holiday added a...</td>\n",
       "      <td>Kwanzaa</td>\n",
       "      <td>the professor who created this holiday added a...</td>\n",
       "      <td>kwanzaa</td>\n",
       "      <td>naacp</td>\n",
       "      <td>the professor who created this holiday added a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3907</td>\n",
       "      <td>2001-09-04</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>MARK TWAIN SEZ</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>In an essay, Twain said surely no language is ...</td>\n",
       "      <td>German</td>\n",
       "      <td>in an essay twain said surely no language is s...</td>\n",
       "      <td>german</td>\n",
       "      <td>mark twain sez</td>\n",
       "      <td>in an essay twain said surely no language is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5306</td>\n",
       "      <td>2007-10-08</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THIS MEANS WAR!</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>The Hundred Years' War, 1337 to 1453, was foug...</td>\n",
       "      <td>France</td>\n",
       "      <td>the hundred years war 1337 to 1453 was fought ...</td>\n",
       "      <td>france</td>\n",
       "      <td>this means war</td>\n",
       "      <td>the hundred years war 1337 to 1453 was fought ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6114</td>\n",
       "      <td>2011-03-24</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>DANCE WITH ME!</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>In Catholic theology, it's a region reserved f...</td>\n",
       "      <td>limbo</td>\n",
       "      <td>in catholic theology its a region reserved for...</td>\n",
       "      <td>limbo</td>\n",
       "      <td>dance with me</td>\n",
       "      <td>in catholic theology its a region reserved for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4837</td>\n",
       "      <td>2005-09-27</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>GONE WITH THE WIND</td>\n",
       "      <td>800.0</td>\n",
       "      <td>In 1968, this sewing machine company's New Yor...</td>\n",
       "      <td>Singer</td>\n",
       "      <td>in 1968 this sewing machine companys new york ...</td>\n",
       "      <td>singer</td>\n",
       "      <td>gone with the wind</td>\n",
       "      <td>in 1968 this sewing machine companys new york ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5759</td>\n",
       "      <td>2009-10-01</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>STUPID ANSWERS: GERMAN EDITION</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Ein Museum fur moderne Kunst is this specific ...</td>\n",
       "      <td>a museum of modern art</td>\n",
       "      <td>ein museum fur moderne kunst is this specific ...</td>\n",
       "      <td>a museum of modern art</td>\n",
       "      <td>stupid answers german edition</td>\n",
       "      <td>ein museum fur moderne kunst is this specific ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3319</td>\n",
       "      <td>1999-01-28</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PAPERBACK WRITERS</td>\n",
       "      <td>500.0</td>\n",
       "      <td>This thriller writer was set when she earned $...</td>\n",
       "      <td>Mary Higgins Clark</td>\n",
       "      <td>this thriller writer was set when she earned 1...</td>\n",
       "      <td>mary higgins clark</td>\n",
       "      <td>paperback writers</td>\n",
       "      <td>this thriller writer was set when she earned 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3557</td>\n",
       "      <td>2000-02-08</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>HOT ENOUGH FOR YOU?</td>\n",
       "      <td>200.0</td>\n",
       "      <td>The Union of Concerned Scientists says thermal...</td>\n",
       "      <td>Sea level</td>\n",
       "      <td>the union of concerned scientists says thermal...</td>\n",
       "      <td>sea level</td>\n",
       "      <td>hot enough for you</td>\n",
       "      <td>the union of concerned scientists says thermal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5458</td>\n",
       "      <td>2008-05-07</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>I LIKE TO DECORATE</td>\n",
       "      <td>400.0</td>\n",
       "      <td>My parties on the theme of this traditional fe...</td>\n",
       "      <td>luau</td>\n",
       "      <td>my parties on the theme of this traditional fe...</td>\n",
       "      <td>luau</td>\n",
       "      <td>i like to decorate</td>\n",
       "      <td>my parties on the theme of this traditional fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3115</td>\n",
       "      <td>1998-02-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>WORLD CAPITALS</td>\n",
       "      <td>500.0</td>\n",
       "      <td>A revolving restaurant spins atop the hot wate...</td>\n",
       "      <td>Reykjavik</td>\n",
       "      <td>a revolving restaurant spins atop the hot wate...</td>\n",
       "      <td>reykjavik</td>\n",
       "      <td>world capitals</td>\n",
       "      <td>a revolving restaurant spins atop the hot wate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4390</td>\n",
       "      <td>2003-10-10</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>BAG \"DAD\"</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>A thingamabob or trinket</td>\n",
       "      <td>doodad</td>\n",
       "      <td>a thingamabob or trinket</td>\n",
       "      <td>doodad</td>\n",
       "      <td>bag dad</td>\n",
       "      <td>a thingamabob or trinket doodad bag dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>5587</td>\n",
       "      <td>2008-12-16</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>400.0</td>\n",
       "      <td>The name of this preserve often made from oran...</td>\n",
       "      <td>marmalade</td>\n",
       "      <td>the name of this preserve often made from oran...</td>\n",
       "      <td>marmalade</td>\n",
       "      <td>food</td>\n",
       "      <td>the name of this preserve often made from oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>5619</td>\n",
       "      <td>2009-01-29</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>THIS MEANS \"WAR\"</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>Have some cherry pie &amp; name &lt;a href=\"http://ww...</td>\n",
       "      <td>Warrant</td>\n",
       "      <td>have some cherry pie  name this group</td>\n",
       "      <td>warrant</td>\n",
       "      <td>this means war</td>\n",
       "      <td>have some cherry pie  name this group warrant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>5944</td>\n",
       "      <td>2010-06-17</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>COMPLETE THE MOVIE QUOTE</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>\"Fargo\":  \"And I guess that was your accomplic...</td>\n",
       "      <td>wood chipper</td>\n",
       "      <td>fargo  and i guess that was your accomplice in...</td>\n",
       "      <td>wood chipper</td>\n",
       "      <td>complete the movie quote</td>\n",
       "      <td>fargo  and i guess that was your accomplice in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>6290</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FLOAT SAM &amp; JET SAM</td>\n",
       "      <td>200.0</td>\n",
       "      <td>In 1613 British Admiral Samuel Argall sailed u...</td>\n",
       "      <td>Pocahontas</td>\n",
       "      <td>in 1613 british admiral samuel argall sailed u...</td>\n",
       "      <td>pocahontas</td>\n",
       "      <td>float sam  jet sam</td>\n",
       "      <td>in 1613 british admiral samuel argall sailed u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>4816</td>\n",
       "      <td>2005-07-11</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>DODGER</td>\n",
       "      <td>800.0</td>\n",
       "      <td>In 1981 this Dodger pitcher nicknamed \"El Toro...</td>\n",
       "      <td>(Fernando) Valenzuela</td>\n",
       "      <td>in 1981 this dodger pitcher nicknamed el toro ...</td>\n",
       "      <td>fernando valenzuela</td>\n",
       "      <td>dodger</td>\n",
       "      <td>in 1981 this dodger pitcher nicknamed el toro ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>4966</td>\n",
       "      <td>2006-03-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ONOMATOPOEIA</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>This word that describes a tearful cry is a ho...</td>\n",
       "      <td>a bawl</td>\n",
       "      <td>this word that describes a tearful cry is a ho...</td>\n",
       "      <td>a bawl</td>\n",
       "      <td>onomatopoeia</td>\n",
       "      <td>this word that describes a tearful cry is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2145</th>\n",
       "      <td>1199</td>\n",
       "      <td>1989-11-16</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>WORLD GEOGRAPHY</td>\n",
       "      <td>500.0</td>\n",
       "      <td>There used to be 2 countries with this name; n...</td>\n",
       "      <td>Congo</td>\n",
       "      <td>there used to be 2 countries with this name no...</td>\n",
       "      <td>congo</td>\n",
       "      <td>world geography</td>\n",
       "      <td>there used to be 2 countries with this name no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2146</th>\n",
       "      <td>3574</td>\n",
       "      <td>2000-03-02</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>\"S\" &amp; \"M\"</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>Georgia site seen &lt;a href=\"http://www.j-archiv...</td>\n",
       "      <td>Stone Mountain</td>\n",
       "      <td>georgia site seen here</td>\n",
       "      <td>stone mountain</td>\n",
       "      <td>s  m</td>\n",
       "      <td>georgia site seen here stone mountain s  m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>3563</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>BAD NEWS</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Philip II learned that his 1588 invasion of En...</td>\n",
       "      <td>Spanish Armada</td>\n",
       "      <td>philip ii learned that his 1588 invasion of en...</td>\n",
       "      <td>spanish armada</td>\n",
       "      <td>bad news</td>\n",
       "      <td>philip ii learned that his 1588 invasion of en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148</th>\n",
       "      <td>1426</td>\n",
       "      <td>1990-11-12</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>RULERS</td>\n",
       "      <td>200.0</td>\n",
       "      <td>At her execution in 1587, this Scottish queen ...</td>\n",
       "      <td>Mary, Queen of Scots</td>\n",
       "      <td>at her execution in 1587 this scottish queen s...</td>\n",
       "      <td>mary queen of scots</td>\n",
       "      <td>rulers</td>\n",
       "      <td>at her execution in 1587 this scottish queen s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>5694</td>\n",
       "      <td>2009-05-14</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ECON 101</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Alliterative term for what you've got when spe...</td>\n",
       "      <td>a balanced budget</td>\n",
       "      <td>alliterative term for what youve got when spen...</td>\n",
       "      <td>a balanced budget</td>\n",
       "      <td>econ 101</td>\n",
       "      <td>alliterative term for what youve got when spen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>5828</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>YOU'VE BEEN TRADED</td>\n",
       "      <td>200.0</td>\n",
       "      <td>On Dec. 26, 1919 the Red Sox traded this man t...</td>\n",
       "      <td>Babe Ruth</td>\n",
       "      <td>on dec 26 1919 the red sox traded this man to ...</td>\n",
       "      <td>babe ruth</td>\n",
       "      <td>youve been traded</td>\n",
       "      <td>on dec 26 1919 the red sox traded this man to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>4639</td>\n",
       "      <td>2004-11-05</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>EVENTS IN THE OLYMPIC DECATHLON</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>The 2 events with \"jump\" in their names</td>\n",
       "      <td>long jump &amp; high jump</td>\n",
       "      <td>the 2 events with jump in their names</td>\n",
       "      <td>long jump  high jump</td>\n",
       "      <td>events in the olympic decathlon</td>\n",
       "      <td>the 2 events with jump in their names long jum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>5547</td>\n",
       "      <td>2008-10-21</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>BORN TO BE MILD</td>\n",
       "      <td>600.0</td>\n",
       "      <td>This writer began communing with nature on Jul...</td>\n",
       "      <td>Henry David Thoreau</td>\n",
       "      <td>this writer began communing with nature on jul...</td>\n",
       "      <td>henry david thoreau</td>\n",
       "      <td>born to be mild</td>\n",
       "      <td>this writer began communing with nature on jul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>4533</td>\n",
       "      <td>2004-04-28</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ELTON JOHN SONGS</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>\"I can't light no more of your darkness, all m...</td>\n",
       "      <td>\"Don't Let The Sun Go Down On Me\"</td>\n",
       "      <td>i cant light no more of your darkness all my p...</td>\n",
       "      <td>dont let the sun go down on me</td>\n",
       "      <td>elton john songs</td>\n",
       "      <td>i cant light no more of your darkness all my p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>3698</td>\n",
       "      <td>2000-10-04</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>MUSICALS</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Lois Lane is the heroine of the musical \"It's ...</td>\n",
       "      <td>Superman</td>\n",
       "      <td>lois lane is the heroine of the musical its a ...</td>\n",
       "      <td>superman</td>\n",
       "      <td>musicals</td>\n",
       "      <td>lois lane is the heroine of the musical its a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>2055</td>\n",
       "      <td>1993-07-09</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>1899</td>\n",
       "      <td>100.0</td>\n",
       "      <td>In June this outlaw led The Sundance Kid and t...</td>\n",
       "      <td>Butch Cassidy</td>\n",
       "      <td>in june this outlaw led the sundance kid and t...</td>\n",
       "      <td>butch cassidy</td>\n",
       "      <td>1899</td>\n",
       "      <td>in june this outlaw led the sundance kid and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>1424</td>\n",
       "      <td>1990-11-08</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>FOOD</td>\n",
       "      <td>200.0</td>\n",
       "      <td>When spaghetti is cooked \"al dente\", it means ...</td>\n",
       "      <td>the teeth</td>\n",
       "      <td>when spaghetti is cooked al dente it means its...</td>\n",
       "      <td>the teeth</td>\n",
       "      <td>food</td>\n",
       "      <td>when spaghetti is cooked al dente it means its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>5218</td>\n",
       "      <td>2007-04-25</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>THE HERMIT</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Part of each day as a hermit might include thi...</td>\n",
       "      <td>flagellation</td>\n",
       "      <td>part of each day as a hermit might include thi...</td>\n",
       "      <td>flagellation</td>\n",
       "      <td>the hermit</td>\n",
       "      <td>part of each day as a hermit might include thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>6027</td>\n",
       "      <td>2010-11-23</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>PASS THE \"URK\"-Y</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Known for their courage &amp; ferocity, these Nepa...</td>\n",
       "      <td>Gurkhas</td>\n",
       "      <td>known for their courage  ferocity these nepale...</td>\n",
       "      <td>gurkhas</td>\n",
       "      <td>pass the urky</td>\n",
       "      <td>known for their courage  ferocity these nepale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>3634</td>\n",
       "      <td>2000-05-25</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>HELLO KITTY</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Riddle me this: Despite its name, you'd be har...</td>\n",
       "      <td>Sphinx</td>\n",
       "      <td>riddle me this despite its name youd be hard p...</td>\n",
       "      <td>sphinx</td>\n",
       "      <td>hello kitty</td>\n",
       "      <td>riddle me this despite its name youd be hard p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>3648</td>\n",
       "      <td>2000-06-14</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>OREGONE</td>\n",
       "      <td>400.0</td>\n",
       "      <td>A grand hotel on what's now this city's Pionee...</td>\n",
       "      <td>Portland</td>\n",
       "      <td>a grand hotel on whats now this citys pioneer ...</td>\n",
       "      <td>portland</td>\n",
       "      <td>oregone</td>\n",
       "      <td>a grand hotel on whats now this citys pioneer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>3938</td>\n",
       "      <td>2001-10-17</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>SPORTS PEOPLE WHO ARE PLACES</td>\n",
       "      <td>200.0</td>\n",
       "      <td>If he blows a last second shot for the N.Y. Kn...</td>\n",
       "      <td>Allan Houston</td>\n",
       "      <td>if he blows a last second shot for the ny knic...</td>\n",
       "      <td>allan houston</td>\n",
       "      <td>sports people who are places</td>\n",
       "      <td>if he blows a last second shot for the ny knic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>5634</td>\n",
       "      <td>2009-02-19</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>GO DIRECTLY TO YALE</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Both George W. Bush &amp; this 2004 election oppon...</td>\n",
       "      <td>John Kerry</td>\n",
       "      <td>both george w bush  this 2004 election opponen...</td>\n",
       "      <td>john kerry</td>\n",
       "      <td>go directly to yale</td>\n",
       "      <td>both george w bush  this 2004 election opponen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>3193</td>\n",
       "      <td>1998-06-17</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ANAGRAMMED COUNTRIES</td>\n",
       "      <td>500.0</td>\n",
       "      <td>Sand Hour</td>\n",
       "      <td>Honduras</td>\n",
       "      <td>sand hour</td>\n",
       "      <td>honduras</td>\n",
       "      <td>anagrammed countries</td>\n",
       "      <td>sand hour honduras anagrammed countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>5449</td>\n",
       "      <td>2008-04-24</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>A GAME OF CHESS</td>\n",
       "      <td>600.0</td>\n",
       "      <td>It's the only chess piece that can jump over o...</td>\n",
       "      <td>the knight</td>\n",
       "      <td>its the only chess piece that can jump over ot...</td>\n",
       "      <td>the knight</td>\n",
       "      <td>a game of chess</td>\n",
       "      <td>its the only chess piece that can jump over ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>4352</td>\n",
       "      <td>2003-07-01</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>TV HOSPITALS</td>\n",
       "      <td>600.0</td>\n",
       "      <td>On this series that debuted in 1972, Squad 51 ...</td>\n",
       "      <td>Emergency!</td>\n",
       "      <td>on this series that debuted in 1972 squad 51 t...</td>\n",
       "      <td>emergency</td>\n",
       "      <td>tv hospitals</td>\n",
       "      <td>on this series that debuted in 1972 squad 51 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>2048</td>\n",
       "      <td>1993-06-30</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FASHION</td>\n",
       "      <td>300.0</td>\n",
       "      <td>The usual color of the 19th century women's bl...</td>\n",
       "      <td>red</td>\n",
       "      <td>the usual color of the 19th century womens blo...</td>\n",
       "      <td>red</td>\n",
       "      <td>fashion</td>\n",
       "      <td>the usual color of the 19th century womens blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>3845</td>\n",
       "      <td>2001-04-27</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>COULD YOU TRANSLATE THAT FOR ME?</td>\n",
       "      <td>200.0</td>\n",
       "      <td>It's the English translation of the German wor...</td>\n",
       "      <td>sweetheart</td>\n",
       "      <td>its the english translation of the german word...</td>\n",
       "      <td>sweetheart</td>\n",
       "      <td>could you translate that for me</td>\n",
       "      <td>its the english translation of the german word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>4513</td>\n",
       "      <td>2004-03-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>MADONNA SONGS</td>\n",
       "      <td>200.0</td>\n",
       "      <td>A \"pure\" hit: \"Touched for the very first time\"</td>\n",
       "      <td>Like A Virgin</td>\n",
       "      <td>a pure hit touched for the very first time</td>\n",
       "      <td>like a virgin</td>\n",
       "      <td>madonna songs</td>\n",
       "      <td>a pure hit touched for the very first time lik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2168 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Show Number   Air Date             Round  \\\n",
       "0            4666 2004-12-13         Jeopardy!   \n",
       "1            5549 2008-10-23         Jeopardy!   \n",
       "2            6238 2011-11-02         Jeopardy!   \n",
       "3            4657 2004-11-30  Double Jeopardy!   \n",
       "4            2873 1997-02-12         Jeopardy!   \n",
       "5             968 1988-11-16  Double Jeopardy!   \n",
       "6            4646 2004-11-15         Jeopardy!   \n",
       "7            4031 2002-02-25  Double Jeopardy!   \n",
       "8            4455 2004-01-09         Jeopardy!   \n",
       "9            3019 1997-10-16  Double Jeopardy!   \n",
       "10           5468 2008-05-21         Jeopardy!   \n",
       "11           4684 2005-01-06         Jeopardy!   \n",
       "12           4538 2004-05-05  Double Jeopardy!   \n",
       "13           3014 1997-10-09         Jeopardy!   \n",
       "14           3637 2000-05-30  Double Jeopardy!   \n",
       "15           5122 2006-12-12  Double Jeopardy!   \n",
       "16           3495 1999-11-12  Double Jeopardy!   \n",
       "17           5600 2009-01-02         Jeopardy!   \n",
       "18           4255 2003-02-14         Jeopardy!   \n",
       "19           4542 2004-05-11         Jeopardy!   \n",
       "20           3907 2001-09-04  Double Jeopardy!   \n",
       "21           5306 2007-10-08         Jeopardy!   \n",
       "22           6114 2011-03-24  Double Jeopardy!   \n",
       "23           4837 2005-09-27  Double Jeopardy!   \n",
       "24           5759 2009-10-01         Jeopardy!   \n",
       "25           3319 1999-01-28         Jeopardy!   \n",
       "26           3557 2000-02-08  Double Jeopardy!   \n",
       "27           5458 2008-05-07         Jeopardy!   \n",
       "28           3115 1998-02-27         Jeopardy!   \n",
       "29           4390 2003-10-10  Double Jeopardy!   \n",
       "...           ...        ...               ...   \n",
       "2139         5587 2008-12-16  Double Jeopardy!   \n",
       "2140         5619 2009-01-29  Double Jeopardy!   \n",
       "2141         5944 2010-06-17  Double Jeopardy!   \n",
       "2142         6290 2012-01-13         Jeopardy!   \n",
       "2143         4816 2005-07-11         Jeopardy!   \n",
       "2144         4966 2006-03-27         Jeopardy!   \n",
       "2145         1199 1989-11-16         Jeopardy!   \n",
       "2146         3574 2000-03-02  Double Jeopardy!   \n",
       "2147         3563 2000-02-16         Jeopardy!   \n",
       "2148         1426 1990-11-12  Double Jeopardy!   \n",
       "2149         5694 2009-05-14         Jeopardy!   \n",
       "2150         5828 2010-01-06         Jeopardy!   \n",
       "2151         4639 2004-11-05  Double Jeopardy!   \n",
       "2152         5547 2008-10-21         Jeopardy!   \n",
       "2153         4533 2004-04-28  Double Jeopardy!   \n",
       "2154         3698 2000-10-04  Double Jeopardy!   \n",
       "2155         2055 1993-07-09         Jeopardy!   \n",
       "2156         1424 1990-11-08  Double Jeopardy!   \n",
       "2157         5218 2007-04-25  Double Jeopardy!   \n",
       "2158         6027 2010-11-23         Jeopardy!   \n",
       "2159         3634 2000-05-25  Double Jeopardy!   \n",
       "2160         3648 2000-06-14  Double Jeopardy!   \n",
       "2161         3938 2001-10-17  Double Jeopardy!   \n",
       "2162         5634 2009-02-19         Jeopardy!   \n",
       "2163         3193 1998-06-17         Jeopardy!   \n",
       "2164         5449 2008-04-24         Jeopardy!   \n",
       "2165         4352 2003-07-01         Jeopardy!   \n",
       "2166         2048 1993-06-30         Jeopardy!   \n",
       "2167         3845 2001-04-27         Jeopardy!   \n",
       "2168         4513 2004-03-31         Jeopardy!   \n",
       "\n",
       "                              Category   Value  \\\n",
       "0           DON WE NOW OUR GUY APPAREL   200.0   \n",
       "1                                VERBS  1000.0   \n",
       "2                            PAY BALL!   600.0   \n",
       "3                           FUNNY HATS  2000.0   \n",
       "4                        WOMEN AUTHORS   200.0   \n",
       "5                         FAMOUS WOMEN   400.0   \n",
       "6                       HORNED ANIMALS   800.0   \n",
       "7                     BEHIND THE MUSIC   800.0   \n",
       "8                             RITE ON!   400.0   \n",
       "9                          STRAIT TALK  1000.0   \n",
       "10                           POTPOURRI   200.0   \n",
       "11               NOW THAT'S INVENTIVE!   200.0   \n",
       "12                 CHARACTERS IN BOOKS  1200.0   \n",
       "13                            TV TWINS   200.0   \n",
       "14                            \"HOTEL\"s   800.0   \n",
       "15               CHURCHES & CATHEDRALS  2000.0   \n",
       "16                      STORY PROBLEMS   800.0   \n",
       "17                     \"F\" I DO SAY SO  1000.0   \n",
       "18                   NECCO SWEETHEARTS   200.0   \n",
       "19                             N\"AA\"CP   400.0   \n",
       "20                      MARK TWAIN SEZ  1000.0   \n",
       "21                     THIS MEANS WAR!  1000.0   \n",
       "22                      DANCE WITH ME!  2000.0   \n",
       "23                  GONE WITH THE WIND   800.0   \n",
       "24      STUPID ANSWERS: GERMAN EDITION   800.0   \n",
       "25                   PAPERBACK WRITERS   500.0   \n",
       "26                 HOT ENOUGH FOR YOU?   200.0   \n",
       "27                  I LIKE TO DECORATE   400.0   \n",
       "28                      WORLD CAPITALS   500.0   \n",
       "29                           BAG \"DAD\"  1200.0   \n",
       "...                                ...     ...   \n",
       "2139                              FOOD   400.0   \n",
       "2140                  THIS MEANS \"WAR\"  1200.0   \n",
       "2141          COMPLETE THE MOVIE QUOTE  1600.0   \n",
       "2142               FLOAT SAM & JET SAM   200.0   \n",
       "2143                            DODGER   800.0   \n",
       "2144                      ONOMATOPOEIA  1000.0   \n",
       "2145                   WORLD GEOGRAPHY   500.0   \n",
       "2146                         \"S\" & \"M\"  2500.0   \n",
       "2147                          BAD NEWS   300.0   \n",
       "2148                            RULERS   200.0   \n",
       "2149                          ECON 101   800.0   \n",
       "2150                YOU'VE BEEN TRADED   200.0   \n",
       "2151   EVENTS IN THE OLYMPIC DECATHLON  1600.0   \n",
       "2152                   BORN TO BE MILD   600.0   \n",
       "2153                  ELTON JOHN SONGS  2000.0   \n",
       "2154                          MUSICALS   200.0   \n",
       "2155                              1899   100.0   \n",
       "2156                              FOOD   200.0   \n",
       "2157                        THE HERMIT  2000.0   \n",
       "2158                  PASS THE \"URK\"-Y  1000.0   \n",
       "2159                       HELLO KITTY  1000.0   \n",
       "2160                           OREGONE   400.0   \n",
       "2161      SPORTS PEOPLE WHO ARE PLACES   200.0   \n",
       "2162               GO DIRECTLY TO YALE   200.0   \n",
       "2163              ANAGRAMMED COUNTRIES   500.0   \n",
       "2164                   A GAME OF CHESS   600.0   \n",
       "2165                      TV HOSPITALS   600.0   \n",
       "2166                           FASHION   300.0   \n",
       "2167  COULD YOU TRANSLATE THAT FOR ME?   200.0   \n",
       "2168                     MADONNA SONGS   200.0   \n",
       "\n",
       "                                               Question  \\\n",
       "0     The 2 numbers on a man's dress shirt, 16/34 fo...   \n",
       "1     This verb means to use another's work without ...   \n",
       "2     This player nicknamed \"Big Papi\" pulls down $1...   \n",
       "3     In Wagner's operas, this eldest Valkyrie is st...   \n",
       "4     Kim Wozencraft & Dorothy Uhnak used their expe...   \n",
       "5     In 1955 this miniskirt innovator opened her fi...   \n",
       "6     This North American animal's population had dr...   \n",
       "7     <a href=\"http://www.j-archive.com/media/2002-0...   \n",
       "8     Among the 5 pillars of this religion is Salat,...   \n",
       "9     On July 3, 1988 an Iranian airliner enroute to...   \n",
       "10    A special flower for April, it can be oxeye or...   \n",
       "11    In 1889 this Elizabethport, New Jersey company...   \n",
       "12    With a little imagination & his purple crayon,...   \n",
       "13    Name shared by Phoebe's twin (also played by L...   \n",
       "14    Greta Garbo & John Barrymore are 2 of the gues...   \n",
       "15    In Ulm, Germany the tallest spire in the world...   \n",
       "16    Hank's mobile home is this long, 1 3/4 times l...   \n",
       "17    This compound word is a forward artillery posi...   \n",
       "18    2-letter word that precedes \"mine\", \"good\" & \"...   \n",
       "19    The professor who created this holiday added a...   \n",
       "20    In an essay, Twain said surely no language is ...   \n",
       "21    The Hundred Years' War, 1337 to 1453, was foug...   \n",
       "22    In Catholic theology, it's a region reserved f...   \n",
       "23    In 1968, this sewing machine company's New Yor...   \n",
       "24    Ein Museum fur moderne Kunst is this specific ...   \n",
       "25    This thriller writer was set when she earned $...   \n",
       "26    The Union of Concerned Scientists says thermal...   \n",
       "27    My parties on the theme of this traditional fe...   \n",
       "28    A revolving restaurant spins atop the hot wate...   \n",
       "29                             A thingamabob or trinket   \n",
       "...                                                 ...   \n",
       "2139  The name of this preserve often made from oran...   \n",
       "2140  Have some cherry pie & name <a href=\"http://ww...   \n",
       "2141  \"Fargo\":  \"And I guess that was your accomplic...   \n",
       "2142  In 1613 British Admiral Samuel Argall sailed u...   \n",
       "2143  In 1981 this Dodger pitcher nicknamed \"El Toro...   \n",
       "2144  This word that describes a tearful cry is a ho...   \n",
       "2145  There used to be 2 countries with this name; n...   \n",
       "2146  Georgia site seen <a href=\"http://www.j-archiv...   \n",
       "2147  Philip II learned that his 1588 invasion of En...   \n",
       "2148  At her execution in 1587, this Scottish queen ...   \n",
       "2149  Alliterative term for what you've got when spe...   \n",
       "2150  On Dec. 26, 1919 the Red Sox traded this man t...   \n",
       "2151            The 2 events with \"jump\" in their names   \n",
       "2152  This writer began communing with nature on Jul...   \n",
       "2153  \"I can't light no more of your darkness, all m...   \n",
       "2154  Lois Lane is the heroine of the musical \"It's ...   \n",
       "2155  In June this outlaw led The Sundance Kid and t...   \n",
       "2156  When spaghetti is cooked \"al dente\", it means ...   \n",
       "2157  Part of each day as a hermit might include thi...   \n",
       "2158  Known for their courage & ferocity, these Nepa...   \n",
       "2159  Riddle me this: Despite its name, you'd be har...   \n",
       "2160  A grand hotel on what's now this city's Pionee...   \n",
       "2161  If he blows a last second shot for the N.Y. Kn...   \n",
       "2162  Both George W. Bush & this 2004 election oppon...   \n",
       "2163                                          Sand Hour   \n",
       "2164  It's the only chess piece that can jump over o...   \n",
       "2165  On this series that debuted in 1972, Squad 51 ...   \n",
       "2166  The usual color of the 19th century women's bl...   \n",
       "2167  It's the English translation of the German wor...   \n",
       "2168    A \"pure\" hit: \"Touched for the very first time\"   \n",
       "\n",
       "                                 Answer  \\\n",
       "0           neck size and sleeve length   \n",
       "1                             to pirate   \n",
       "2                           David Ortiz   \n",
       "3                             Brunhilde   \n",
       "4                           Policewomen   \n",
       "5                            Mary Quant   \n",
       "6            the buffalo (or the bison)   \n",
       "7                                Grease   \n",
       "8                                 Islam   \n",
       "9                  the Strait of Hormuz   \n",
       "10                              a daisy   \n",
       "11                               Singer   \n",
       "12                               Harold   \n",
       "13                               Ursula   \n",
       "14                          Grand Hotel   \n",
       "15                               gothic   \n",
       "16                              14 feet   \n",
       "17                           a firebase   \n",
       "18                                   be   \n",
       "19                              Kwanzaa   \n",
       "20                               German   \n",
       "21                               France   \n",
       "22                                limbo   \n",
       "23                               Singer   \n",
       "24               a museum of modern art   \n",
       "25                   Mary Higgins Clark   \n",
       "26                            Sea level   \n",
       "27                                 luau   \n",
       "28                            Reykjavik   \n",
       "29                               doodad   \n",
       "...                                 ...   \n",
       "2139                          marmalade   \n",
       "2140                            Warrant   \n",
       "2141                       wood chipper   \n",
       "2142                         Pocahontas   \n",
       "2143              (Fernando) Valenzuela   \n",
       "2144                             a bawl   \n",
       "2145                              Congo   \n",
       "2146                     Stone Mountain   \n",
       "2147                     Spanish Armada   \n",
       "2148               Mary, Queen of Scots   \n",
       "2149                  a balanced budget   \n",
       "2150                          Babe Ruth   \n",
       "2151              long jump & high jump   \n",
       "2152                Henry David Thoreau   \n",
       "2153  \"Don't Let The Sun Go Down On Me\"   \n",
       "2154                           Superman   \n",
       "2155                      Butch Cassidy   \n",
       "2156                          the teeth   \n",
       "2157                       flagellation   \n",
       "2158                            Gurkhas   \n",
       "2159                             Sphinx   \n",
       "2160                           Portland   \n",
       "2161                      Allan Houston   \n",
       "2162                         John Kerry   \n",
       "2163                           Honduras   \n",
       "2164                         the knight   \n",
       "2165                         Emergency!   \n",
       "2166                                red   \n",
       "2167                         sweetheart   \n",
       "2168                      Like A Virgin   \n",
       "\n",
       "                                         clean_question  \\\n",
       "0     the 2 numbers on a mans dress shirt 1634 for e...   \n",
       "1     this verb means to use anothers work without p...   \n",
       "2     this player nicknamed big papi pulls down 125 ...   \n",
       "3     in wagners operas this eldest valkyrie is ster...   \n",
       "4     kim wozencraft  dorothy uhnak used their exper...   \n",
       "5     in 1955 this miniskirt innovator opened her fi...   \n",
       "6     this north american animals population had dro...   \n",
       "7     this 50s high school love story thats thrilled...   \n",
       "8     among the 5 pillars of this religion is salat ...   \n",
       "9     on july 3 1988 an iranian airliner enroute to ...   \n",
       "10    a special flower for april it can be oxeye or ...   \n",
       "11    in 1889 this elizabethport new jersey company ...   \n",
       "12    with a little imagination  his purple crayon h...   \n",
       "13    name shared by phoebes twin also played by lis...   \n",
       "14    greta garbo  john barrymore are 2 of the guest...   \n",
       "15    in ulm germany the tallest spire in the world ...   \n",
       "16    hanks mobile home is this long 1 34 times long...   \n",
       "17    this compound word is a forward artillery posi...   \n",
       "18    2letter word that precedes mine good  true on ...   \n",
       "19    the professor who created this holiday added a...   \n",
       "20    in an essay twain said surely no language is s...   \n",
       "21    the hundred years war 1337 to 1453 was fought ...   \n",
       "22    in catholic theology its a region reserved for...   \n",
       "23    in 1968 this sewing machine companys new york ...   \n",
       "24    ein museum fur moderne kunst is this specific ...   \n",
       "25    this thriller writer was set when she earned 1...   \n",
       "26    the union of concerned scientists says thermal...   \n",
       "27    my parties on the theme of this traditional fe...   \n",
       "28    a revolving restaurant spins atop the hot wate...   \n",
       "29                             a thingamabob or trinket   \n",
       "...                                                 ...   \n",
       "2139  the name of this preserve often made from oran...   \n",
       "2140              have some cherry pie  name this group   \n",
       "2141  fargo  and i guess that was your accomplice in...   \n",
       "2142  in 1613 british admiral samuel argall sailed u...   \n",
       "2143  in 1981 this dodger pitcher nicknamed el toro ...   \n",
       "2144  this word that describes a tearful cry is a ho...   \n",
       "2145  there used to be 2 countries with this name no...   \n",
       "2146                             georgia site seen here   \n",
       "2147  philip ii learned that his 1588 invasion of en...   \n",
       "2148  at her execution in 1587 this scottish queen s...   \n",
       "2149  alliterative term for what youve got when spen...   \n",
       "2150  on dec 26 1919 the red sox traded this man to ...   \n",
       "2151              the 2 events with jump in their names   \n",
       "2152  this writer began communing with nature on jul...   \n",
       "2153  i cant light no more of your darkness all my p...   \n",
       "2154  lois lane is the heroine of the musical its a ...   \n",
       "2155  in june this outlaw led the sundance kid and t...   \n",
       "2156  when spaghetti is cooked al dente it means its...   \n",
       "2157  part of each day as a hermit might include thi...   \n",
       "2158  known for their courage  ferocity these nepale...   \n",
       "2159  riddle me this despite its name youd be hard p...   \n",
       "2160  a grand hotel on whats now this citys pioneer ...   \n",
       "2161  if he blows a last second shot for the ny knic...   \n",
       "2162  both george w bush  this 2004 election opponen...   \n",
       "2163                                          sand hour   \n",
       "2164  its the only chess piece that can jump over ot...   \n",
       "2165  on this series that debuted in 1972 squad 51 t...   \n",
       "2166  the usual color of the 19th century womens blo...   \n",
       "2167  its the english translation of the german word...   \n",
       "2168         a pure hit touched for the very first time   \n",
       "\n",
       "                        clean_answer                   clean_category  \\\n",
       "0        neck size and sleeve length       don we now our guy apparel   \n",
       "1                          to pirate                            verbs   \n",
       "2                        david ortiz                         pay ball   \n",
       "3                          brunhilde                       funny hats   \n",
       "4                        policewomen                    women authors   \n",
       "5                         mary quant                     famous women   \n",
       "6           the buffalo or the bison                   horned animals   \n",
       "7                             grease                 behind the music   \n",
       "8                              islam                          rite on   \n",
       "9               the strait of hormuz                      strait talk   \n",
       "10                           a daisy                        potpourri   \n",
       "11                            singer              now thats inventive   \n",
       "12                            harold              characters in books   \n",
       "13                            ursula                         tv twins   \n",
       "14                       grand hotel                           hotels   \n",
       "15                            gothic             churches  cathedrals   \n",
       "16                           14 feet                   story problems   \n",
       "17                        a firebase                    f i do say so   \n",
       "18                                be                necco sweethearts   \n",
       "19                           kwanzaa                            naacp   \n",
       "20                            german                   mark twain sez   \n",
       "21                            france                   this means war   \n",
       "22                             limbo                    dance with me   \n",
       "23                            singer               gone with the wind   \n",
       "24            a museum of modern art    stupid answers german edition   \n",
       "25                mary higgins clark                paperback writers   \n",
       "26                         sea level               hot enough for you   \n",
       "27                              luau               i like to decorate   \n",
       "28                         reykjavik                   world capitals   \n",
       "29                            doodad                          bag dad   \n",
       "...                              ...                              ...   \n",
       "2139                       marmalade                             food   \n",
       "2140                         warrant                   this means war   \n",
       "2141                    wood chipper         complete the movie quote   \n",
       "2142                      pocahontas               float sam  jet sam   \n",
       "2143             fernando valenzuela                           dodger   \n",
       "2144                          a bawl                     onomatopoeia   \n",
       "2145                           congo                  world geography   \n",
       "2146                  stone mountain                             s  m   \n",
       "2147                  spanish armada                         bad news   \n",
       "2148             mary queen of scots                           rulers   \n",
       "2149               a balanced budget                         econ 101   \n",
       "2150                       babe ruth                youve been traded   \n",
       "2151            long jump  high jump  events in the olympic decathlon   \n",
       "2152             henry david thoreau                  born to be mild   \n",
       "2153  dont let the sun go down on me                 elton john songs   \n",
       "2154                        superman                         musicals   \n",
       "2155                   butch cassidy                             1899   \n",
       "2156                       the teeth                             food   \n",
       "2157                    flagellation                       the hermit   \n",
       "2158                         gurkhas                    pass the urky   \n",
       "2159                          sphinx                      hello kitty   \n",
       "2160                        portland                          oregone   \n",
       "2161                   allan houston     sports people who are places   \n",
       "2162                      john kerry              go directly to yale   \n",
       "2163                        honduras             anagrammed countries   \n",
       "2164                      the knight                  a game of chess   \n",
       "2165                       emergency                     tv hospitals   \n",
       "2166                             red                          fashion   \n",
       "2167                      sweetheart  could you translate that for me   \n",
       "2168                   like a virgin                    madonna songs   \n",
       "\n",
       "                                             everything  \n",
       "0     the 2 numbers on a mans dress shirt 1634 for e...  \n",
       "1     this verb means to use anothers work without p...  \n",
       "2     this player nicknamed big papi pulls down 125 ...  \n",
       "3     in wagners operas this eldest valkyrie is ster...  \n",
       "4     kim wozencraft  dorothy uhnak used their exper...  \n",
       "5     in 1955 this miniskirt innovator opened her fi...  \n",
       "6     this north american animals population had dro...  \n",
       "7     this 50s high school love story thats thrilled...  \n",
       "8     among the 5 pillars of this religion is salat ...  \n",
       "9     on july 3 1988 an iranian airliner enroute to ...  \n",
       "10    a special flower for april it can be oxeye or ...  \n",
       "11    in 1889 this elizabethport new jersey company ...  \n",
       "12    with a little imagination  his purple crayon h...  \n",
       "13    name shared by phoebes twin also played by lis...  \n",
       "14    greta garbo  john barrymore are 2 of the guest...  \n",
       "15    in ulm germany the tallest spire in the world ...  \n",
       "16    hanks mobile home is this long 1 34 times long...  \n",
       "17    this compound word is a forward artillery posi...  \n",
       "18    2letter word that precedes mine good  true on ...  \n",
       "19    the professor who created this holiday added a...  \n",
       "20    in an essay twain said surely no language is s...  \n",
       "21    the hundred years war 1337 to 1453 was fought ...  \n",
       "22    in catholic theology its a region reserved for...  \n",
       "23    in 1968 this sewing machine companys new york ...  \n",
       "24    ein museum fur moderne kunst is this specific ...  \n",
       "25    this thriller writer was set when she earned 1...  \n",
       "26    the union of concerned scientists says thermal...  \n",
       "27    my parties on the theme of this traditional fe...  \n",
       "28    a revolving restaurant spins atop the hot wate...  \n",
       "29              a thingamabob or trinket doodad bag dad  \n",
       "...                                                 ...  \n",
       "2139  the name of this preserve often made from oran...  \n",
       "2140  have some cherry pie  name this group warrant ...  \n",
       "2141  fargo  and i guess that was your accomplice in...  \n",
       "2142  in 1613 british admiral samuel argall sailed u...  \n",
       "2143  in 1981 this dodger pitcher nicknamed el toro ...  \n",
       "2144  this word that describes a tearful cry is a ho...  \n",
       "2145  there used to be 2 countries with this name no...  \n",
       "2146         georgia site seen here stone mountain s  m  \n",
       "2147  philip ii learned that his 1588 invasion of en...  \n",
       "2148  at her execution in 1587 this scottish queen s...  \n",
       "2149  alliterative term for what youve got when spen...  \n",
       "2150  on dec 26 1919 the red sox traded this man to ...  \n",
       "2151  the 2 events with jump in their names long jum...  \n",
       "2152  this writer began communing with nature on jul...  \n",
       "2153  i cant light no more of your darkness all my p...  \n",
       "2154  lois lane is the heroine of the musical its a ...  \n",
       "2155  in june this outlaw led the sundance kid and t...  \n",
       "2156  when spaghetti is cooked al dente it means its...  \n",
       "2157  part of each day as a hermit might include thi...  \n",
       "2158  known for their courage  ferocity these nepale...  \n",
       "2159  riddle me this despite its name youd be hard p...  \n",
       "2160  a grand hotel on whats now this citys pioneer ...  \n",
       "2161  if he blows a last second shot for the ny knic...  \n",
       "2162  both george w bush  this 2004 election opponen...  \n",
       "2163            sand hour honduras anagrammed countries  \n",
       "2164  its the only chess piece that can jump over ot...  \n",
       "2165  on this series that debuted in 1972 squad 51 t...  \n",
       "2166  the usual color of the 19th century womens blo...  \n",
       "2167  its the english translation of the german word...  \n",
       "2168  a pure hit touched for the very first time lik...  \n",
       "\n",
       "[2168 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_clean_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# questions = df['clean_question'].values\n",
    "questions = df['everything'].values\n",
    "# categories = df['clean_category'].values\n",
    "# answers = df['clean_answer'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use extend so it's a big flat list of vocab\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in questions:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'questions', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>numbers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>mans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dress</th>\n",
       "      <td>dress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shirt</th>\n",
       "      <td>shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exampl</th>\n",
       "      <td>example</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usual</th>\n",
       "      <td>usually</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measur</th>\n",
       "      <td>measurments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>these</th>\n",
       "      <td>these</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>things</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neck</th>\n",
       "      <td>neck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sleev</th>\n",
       "      <td>sleeve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>length</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words\n",
       "the             the\n",
       "number      numbers\n",
       "on               on\n",
       "a                 a\n",
       "man            mans\n",
       "dress         dress\n",
       "shirt         shirt\n",
       "for             for\n",
       "exampl      example\n",
       "are             are\n",
       "usual       usually\n",
       "measur  measurments\n",
       "of               of\n",
       "these         these\n",
       "thing        things\n",
       "neck           neck\n",
       "size           size\n",
       "and             and\n",
       "sleev        sleeve\n",
       "length       length"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_test.pkl', 'tfidf_test.pkl_01.npy', 'tfidf_test.pkl_02.npy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "#                                  min_df=0.2, stop_words='english',\n",
    "#                                  use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                                 tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer(stop_words='english',\n",
    "#                                  tokenizer=tokenize_only, ngram_range=(1,3))\n",
    "\n",
    "# %time tfidf_matrix = tfidf_vectorizer.fit_transform(questions)\n",
    "\n",
    "tfidf_vectorizer.fit(questions)\n",
    "\n",
    "# More memory efficient to dump the model and then load it\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = joblib.load('tfidf_test.pkl')\n",
    "tfidf_matrix = tfidf_vectorizer.transform(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.47 s, sys: 64 ms, total: 4.53 s\n",
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 50\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     292\n",
       "13     74\n",
       "23     65\n",
       "24     63\n",
       "28     58\n",
       "29     55\n",
       "16     53\n",
       "27     53\n",
       "6      52\n",
       "17     51\n",
       "21     51\n",
       "40     50\n",
       "32     49\n",
       "11     47\n",
       "5      46\n",
       "47     45\n",
       "37     45\n",
       "15     43\n",
       "48     43\n",
       "8      42\n",
       "25     41\n",
       "3      39\n",
       "20     39\n",
       "22     39\n",
       "12     38\n",
       "34     36\n",
       "43     36\n",
       "39     36\n",
       "44     35\n",
       "38     35\n",
       "26     33\n",
       "33     33\n",
       "42     33\n",
       "31     33\n",
       "7      32\n",
       "46     32\n",
       "41     32\n",
       "36     30\n",
       "35     28\n",
       "2      28\n",
       "19     28\n",
       "45     25\n",
       "10     24\n",
       "9      24\n",
       "30     23\n",
       "18     22\n",
       "49     20\n",
       "1      13\n",
       "0      13\n",
       "14     11\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: pirate, gas, ship, verb, jason,\n",
      "\n",
      "Cluster 1 words: sound, according, music, whistle, sound,\n",
      "\n",
      "Cluster 2 words: century, 19th, 19th, women, married,\n",
      "\n",
      "Cluster 3 words: historically, said, charles, hospital, people,\n",
      "\n",
      "Cluster 4 words: ill, known, stars, middle, make,\n",
      "\n",
      "Cluster 5 words: capitals, world, world, city, paris,\n",
      "\n",
      "Cluster 6 words: city, races, newspapers, annual, college,\n",
      "\n",
      "Cluster 7 words: years, species, animals, bird, kingdom,\n",
      "\n",
      "Cluster 8 words: seen, radio, war, world, world,\n",
      "\n",
      "Cluster 9 words: opened, town, house, massachusetts, miller,\n",
      "\n",
      "Cluster 10 words: stone, elvis, female, mary, presleys,\n",
      "\n",
      "Cluster 11 words: america, use, miss, word, precedes,\n",
      "\n",
      "Cluster 12 words: saintly, born, history, peter, patron,\n",
      "\n",
      "Cluster 13 words: film, titled, movie, asked, come,\n",
      "\n",
      "Cluster 14 words: highest, income, mountain, highest, point,\n",
      "\n",
      "Cluster 15 words: states, shared, oklahoma, official, mississippi,\n",
      "\n",
      "Cluster 16 words: country, became, world, country, future,\n",
      "\n",
      "Cluster 17 words: means, term, phrase, word, origin,\n",
      "\n",
      "Cluster 18 words: william, sir, astronomer, discovering, court,\n",
      "\n",
      "Cluster 19 words: fun, category, prize, mainly, nobel,\n",
      "\n",
      "Cluster 20 words: sea, oil, equals, friends, reserved,\n",
      "\n",
      "Cluster 21 words: lines, game, ball, services, recognize,\n",
      "\n",
      "Cluster 22 words: good, home, land, ways, away,\n",
      "\n",
      "Cluster 23 words: song, music, stands, chicago, classic,\n",
      "\n",
      "Cluster 24 words: word, like, early, egg, vaudeville,\n",
      "\n",
      "Cluster 25 words: food, treat, drinking, brains, activity,\n",
      "\n",
      "Cluster 26 words: war, died, cold, russian, means,\n",
      "\n",
      "Cluster 27 words: nations, park, forest, mount, nations,\n",
      "\n",
      "Cluster 28 words: clue, crew, clue, john, classic,\n",
      "\n",
      "Cluster 29 words: new, york, new, production, leading,\n",
      "\n",
      "Cluster 30 words: blue, gems, henry, jewelry, diamonds,\n",
      "\n",
      "Cluster 31 words: flag, dont, james, oliver, perry,\n",
      "\n",
      "Cluster 32 words: team, world, series, record, win,\n",
      "\n",
      "Cluster 33 words: british, days, elizabeth, queen, remembers,\n",
      "\n",
      "Cluster 34 words: july, naturally, dad, julia, nixon,\n",
      "\n",
      "Cluster 35 words: islands, largest, canadian, country, rhode,\n",
      "\n",
      "Cluster 36 words: operas, love, english, card, presented,\n",
      "\n",
      "Cluster 37 words: lake, body, water, form, body,\n",
      "\n",
      "Cluster 38 words: authors, colorful, pulitzer, purple, walker,\n",
      "\n",
      "Cluster 39 words: rhyming, times, rhyming, agents, celebrates,\n",
      "\n",
      "Cluster 40 words: mans, young, life, old, greatest,\n",
      "\n",
      "Cluster 41 words: hall, major, fame, baseball, hall,\n",
      "\n",
      "Cluster 42 words: french, rose, school, come, cooking,\n",
      "\n",
      "Cluster 43 words: holiday, celebrates, events, trios, men,\n",
      "\n",
      "Cluster 44 words: books, battle, took, war, butter,\n",
      "\n",
      "Cluster 45 words: numbers, senators, states, states, senators,\n",
      "\n",
      "Cluster 46 words: president, presidential, vice, vice, elections,\n",
      "\n",
      "Cluster 47 words: type, cat, only, dog, tail,\n",
      "\n",
      "Cluster 48 words: great, kings, brother, succeeded, alfred,\n",
      "\n",
      "Cluster 49 words: novels, room, chapter, em, view,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "cluster_words = []\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    cluster_words.append([])\n",
    "    for ind in order_centroids[i, :5]: #replace 10 with n words per cluster\n",
    "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "        cluster_words[i].append('%s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'))\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "#     print(\"Cluster %d categories:\" % i, end='')\n",
    "#     for cat in df.ix[i]['Category']#.values.tolist():\n",
    "#         print(' %s,' % title, end='')\n",
    "#     print() #add whitespace\n",
    "#     print() #add whitespace\n",
    "    \n",
    "# print()\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_names = []\n",
    "\n",
    "for item in cluster_words:\n",
    "    string = ''\n",
    "    for i in item:\n",
    "        string += i\n",
    "        string += ' '\n",
    "    cluster_names.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pirate gas ship verb jason ',\n",
       " 'sound according music whistle sound ',\n",
       " 'century 19th 19th women married ',\n",
       " 'historically said charles hospital people ',\n",
       " 'ill known stars middle make ',\n",
       " 'capitals world world city paris ',\n",
       " 'city races newspapers annual college ',\n",
       " 'years species animals bird kingdom ',\n",
       " 'seen radio war world world ',\n",
       " 'opened town house massachusetts miller ',\n",
       " 'stone elvis female mary presleys ',\n",
       " 'america use miss word precedes ',\n",
       " 'saintly born history peter patron ',\n",
       " 'film titled movie asked come ',\n",
       " 'highest income mountain highest point ',\n",
       " 'states shared oklahoma official mississippi ',\n",
       " 'country became world country future ',\n",
       " 'means term phrase word origin ',\n",
       " 'william sir astronomer discovering court ',\n",
       " 'fun category prize mainly nobel ',\n",
       " 'sea oil equals friends reserved ',\n",
       " 'lines game ball services recognize ',\n",
       " 'good home land ways away ',\n",
       " 'song music stands chicago classic ',\n",
       " 'word like early egg vaudeville ',\n",
       " 'food treat drinking brains activity ',\n",
       " 'war died cold russian means ',\n",
       " 'nations park forest mount nations ',\n",
       " 'clue crew clue john classic ',\n",
       " 'new york new production leading ',\n",
       " 'blue gems henry jewelry diamonds ',\n",
       " 'flag dont james oliver perry ',\n",
       " 'team world series record win ',\n",
       " 'british days elizabeth queen remembers ',\n",
       " 'july naturally dad julia nixon ',\n",
       " 'islands largest canadian country rhode ',\n",
       " 'operas love english card presented ',\n",
       " 'lake body water form body ',\n",
       " 'authors colorful pulitzer purple walker ',\n",
       " 'rhyming times rhyming agents celebrates ',\n",
       " 'mans young life old greatest ',\n",
       " 'hall major fame baseball hall ',\n",
       " 'french rose school come cooking ',\n",
       " 'holiday celebrates events trios men ',\n",
       " 'books battle took war butter ',\n",
       " 'numbers senators states states senators ',\n",
       " 'president presidential vice vice elections ',\n",
       " 'type cat only dog tail ',\n",
       " 'great kings brother succeeded alfred ',\n",
       " 'novels room chapter em view ']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Visualization attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os  # for os.path.basename\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "MDS()\n",
    "\n",
    "# convert two components as we're plotting points in a two-dimensional plane\n",
    "# \"precomputed\" because we provide a distance matrix\n",
    "# we will also specify `random_state` so the plot is reproducible.\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
    "\n",
    "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
    "\n",
    "xs, ys = pos[:, 0], pos[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_dict = dict(zip(range(50), cluster_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'pirate gas ship verb jason ',\n",
       " 1: 'sound according music whistle sound ',\n",
       " 2: 'century 19th 19th women married ',\n",
       " 3: 'historically said charles hospital people ',\n",
       " 4: 'ill known stars middle make ',\n",
       " 5: 'capitals world world city paris ',\n",
       " 6: 'city races newspapers annual college ',\n",
       " 7: 'years species animals bird kingdom ',\n",
       " 8: 'seen radio war world world ',\n",
       " 9: 'opened town house massachusetts miller ',\n",
       " 10: 'stone elvis female mary presleys ',\n",
       " 11: 'america use miss word precedes ',\n",
       " 12: 'saintly born history peter patron ',\n",
       " 13: 'film titled movie asked come ',\n",
       " 14: 'highest income mountain highest point ',\n",
       " 15: 'states shared oklahoma official mississippi ',\n",
       " 16: 'country became world country future ',\n",
       " 17: 'means term phrase word origin ',\n",
       " 18: 'william sir astronomer discovering court ',\n",
       " 19: 'fun category prize mainly nobel ',\n",
       " 20: 'sea oil equals friends reserved ',\n",
       " 21: 'lines game ball services recognize ',\n",
       " 22: 'good home land ways away ',\n",
       " 23: 'song music stands chicago classic ',\n",
       " 24: 'word like early egg vaudeville ',\n",
       " 25: 'food treat drinking brains activity ',\n",
       " 26: 'war died cold russian means ',\n",
       " 27: 'nations park forest mount nations ',\n",
       " 28: 'clue crew clue john classic ',\n",
       " 29: 'new york new production leading ',\n",
       " 30: 'blue gems henry jewelry diamonds ',\n",
       " 31: 'flag dont james oliver perry ',\n",
       " 32: 'team world series record win ',\n",
       " 33: 'british days elizabeth queen remembers ',\n",
       " 34: 'july naturally dad julia nixon ',\n",
       " 35: 'islands largest canadian country rhode ',\n",
       " 36: 'operas love english card presented ',\n",
       " 37: 'lake body water form body ',\n",
       " 38: 'authors colorful pulitzer purple walker ',\n",
       " 39: 'rhyming times rhyming agents celebrates ',\n",
       " 40: 'mans young life old greatest ',\n",
       " 41: 'hall major fame baseball hall ',\n",
       " 42: 'french rose school come cooking ',\n",
       " 43: 'holiday celebrates events trios men ',\n",
       " 44: 'books battle took war butter ',\n",
       " 45: 'numbers senators states states senators ',\n",
       " 46: 'president presidential vice vice elections ',\n",
       " 47: 'type cat only dog tail ',\n",
       " 48: 'great kings brother succeeded alfred ',\n",
       " 49: 'novels room chapter em view '}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set up colors per clusters using a dict\n",
    "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-af359ee03d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#group by cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m   3776\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   3777\u001b[0m                        \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3778\u001b[0;31m                        **kwargs)\n\u001b[0m\u001b[1;32m   3779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1425\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, mutated)\u001b[0m\n\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_in_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# df.groupby('name')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m             \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2384\u001b[0m             \u001b[0mexclusions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nick/anaconda2/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "#some ipython magic to show the matplotlib plots inline\n",
    "%matplotlib inline \n",
    "\n",
    "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
    "df = pd.DataFrame(dict(x=xs, y=ys))#, label=clusters, title=titles)) \n",
    "\n",
    "#group by cluster\n",
    "groups = df.groupby('label')\n",
    "\n",
    "\n",
    "# set up plot\n",
    "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
    "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
    "\n",
    "#iterate through groups to layer the plot\n",
    "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, \n",
    "            label=cluster_names[name], color=cluster_colors[name], \n",
    "            mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelbottom='off')\n",
    "    ax.tick_params(\\\n",
    "        axis= 'y',         # changes apply to the y-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        left='off',      # ticks along the bottom edge are off\n",
    "        top='off',         # ticks along the top edge are off\n",
    "        labelleft='off')\n",
    "    \n",
    "ax.legend(numpoints=1)  #show legend with only 1 point\n",
    "\n",
    "#add label in x,y position with the label as the film title\n",
    "for i in range(len(df)):\n",
    "    ax.text(df.ix[i]['x'], df.ix[i]['y'], df.ix[i]['title'], size=8)  \n",
    "\n",
    "    \n",
    "    \n",
    "plt.show() #show the plot\n",
    "\n",
    "#uncomment the below to save the plot if need be\n",
    "#plt.savefig('clusters_small_noaxes.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Attempts - work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#strip any proper names from a text...unfortunately right now this is yanking the first word from a sentence too.\n",
    "def strip_proppers(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word.islower()]\n",
    "    return \"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strip any proper nouns (NNP) or plural proper nouns (NNPS) from a text\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def strip_proppers_POS(text):\n",
    "    tagged = pos_tag(text.split()) #use NLTK's part of speech tagger\n",
    "    non_propernouns = [word for word,pos in tagged if pos != 'NNP' and pos != 'NNPS']\n",
    "    return non_propernouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.21 s, sys: 20 ms, total: 4.23 s\n",
      "Wall time: 4.21 s\n",
      "CPU times: user 9.58 s, sys: 76 ms, total: 9.65 s\n",
      "Wall time: 9.57 s\n",
      "CPU times: user 1.34 s, sys: 28 ms, total: 1.37 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities \n",
    "\n",
    "#remove proper names\n",
    "%time preprocess = [strip_proppers(doc) for doc in questions]\n",
    "\n",
    "#tokenize\n",
    "%time tokenized_text = [tokenize_and_stem(text) for text in preprocess]\n",
    "\n",
    "#remove stop words\n",
    "%time texts = [[word for word in text if word not in stopwords] for text in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a Gensim dictionary from the texts\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "#remove extremes (similar to the min/max df step used when creating the tf-idf matrix)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "\n",
    "#convert the dictionary to a bag of words corpus for reference\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28min 56s, sys: 1.22 s, total: 28min 57s\n",
      "Wall time: 28min 57s\n"
     ]
    }
   ],
   "source": [
    "%time lda = models.LdaModel(corpus, num_topics=5, id2word=dictionary, update_every=5, chunksize=10000, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  u'0.011*citi + 0.011*state + 0.007*countri + 0.007*new + 0.007*name + 0.007*nation + 0.006*one + 0.006*us + 0.006*first + 0.005*world'),\n",
       " (1,\n",
       "  u'0.009*film + 0.009*play + 0.006*titl + 0.005*one + 0.005*show + 0.004*star + 0.004*day + 0.004*song + 0.004*music + 0.004*man'),\n",
       " (2,\n",
       "  u'0.009*one + 0.008*name + 0.008*war + 0.005*first + 0.005*presid + 0.004*henri + 0.003*king + 0.003*seen + 0.003*american + 0.003*year'),\n",
       " (3,\n",
       "  u'0.014*name + 0.006*mean + 0.005*call + 0.005*island + 0.005*king + 0.004*like + 0.004*may + 0.004*one + 0.004*first + 0.003*use'),\n",
       " (4,\n",
       "  u'0.007*type + 0.006*sea + 0.005*name + 0.005*use + 0.004*one + 0.004*clue + 0.004*first + 0.003*anim + 0.003*seen + 0.003*crew')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-c9f79ff99053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtopics_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtopics_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopics_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopic_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence"
     ]
    }
   ],
   "source": [
    "topics_matrix = lda.show_topics(formatted=False, num_words=20)\n",
    "topics_matrix = np.array(topics_matrix)\n",
    "\n",
    "topic_words = topics_matrix[:,:,1]\n",
    "for i in topic_words:\n",
    "    print [str(word) for word in i]\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(topics_matrix)):\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
