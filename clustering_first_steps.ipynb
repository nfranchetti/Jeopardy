{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216930, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/JEOPARDY_CSV.csv', encoding='utf-8')\n",
    "full_df = pd.read_csv('data/JEOPARDY_CSV.csv', encoding='utf-8')\n",
    "print full_df.shape\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = full_df.sample(frac=0.1)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3965</td>\n",
       "      <td>2001-11-23</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FILMS OF THE '70s</td>\n",
       "      <td>$100</td>\n",
       "      <td>Cleavon Little plays Black Bart, the sheriff o...</td>\n",
       "      <td>Blazing Saddles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3279</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FABULOUS BAKER BOYS</td>\n",
       "      <td>$400</td>\n",
       "      <td>Trumpet-playing Baker seen here</td>\n",
       "      <td>Chet Baker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871</td>\n",
       "      <td>1992-10-26</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>OLD MOVIES</td>\n",
       "      <td>$400</td>\n",
       "      <td>Charley Grapewin who played Grandpa Joad in \"T...</td>\n",
       "      <td>The Wizard of Oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3077</td>\n",
       "      <td>1998-01-06</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>COLORFUL WORDS &amp; PHRASES</td>\n",
       "      <td>$600</td>\n",
       "      <td>This colorful Jimi Hendrix classic \"experience...</td>\n",
       "      <td>\"Purple Haze\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4720</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FRUITS &amp; VEGETABLES</td>\n",
       "      <td>$800</td>\n",
       "      <td>It's the leading agricultural product of the i...</td>\n",
       "      <td>bananas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date             Round                  Category  Value  \\\n",
       "0         3965  2001-11-23         Jeopardy!         FILMS OF THE '70s   $100   \n",
       "1         3279  1998-12-03         Jeopardy!       FABULOUS BAKER BOYS   $400   \n",
       "2         1871  1992-10-26  Double Jeopardy!                OLD MOVIES   $400   \n",
       "3         3077  1998-01-06  Double Jeopardy!  COLORFUL WORDS & PHRASES   $600   \n",
       "4         4720  2005-02-25         Jeopardy!       FRUITS & VEGETABLES   $800   \n",
       "\n",
       "                                            Question            Answer  \n",
       "0  Cleavon Little plays Black Bart, the sheriff o...   Blazing Saddles  \n",
       "1                    Trumpet-playing Baker seen here        Chet Baker  \n",
       "2  Charley Grapewin who played Grandpa Joad in \"T...  The Wizard of Oz  \n",
       "3  This colorful Jimi Hendrix classic \"experience...     \"Purple Haze\"  \n",
       "4  It's the leading agricultural product of the i...           bananas  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3965</td>\n",
       "      <td>2001-11-23</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FILMS OF THE '70s</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Cleavon Little plays Black Bart, the sheriff o...</td>\n",
       "      <td>Blazing Saddles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3279</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FABULOUS BAKER BOYS</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Trumpet-playing Baker seen here</td>\n",
       "      <td>Chet Baker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871</td>\n",
       "      <td>1992-10-26</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>OLD MOVIES</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Charley Grapewin who played Grandpa Joad in \"T...</td>\n",
       "      <td>The Wizard of Oz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3077</td>\n",
       "      <td>1998-01-06</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>COLORFUL WORDS &amp; PHRASES</td>\n",
       "      <td>600.0</td>\n",
       "      <td>This colorful Jimi Hendrix classic \"experience...</td>\n",
       "      <td>\"Purple Haze\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4720</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FRUITS &amp; VEGETABLES</td>\n",
       "      <td>800.0</td>\n",
       "      <td>It's the leading agricultural product of the i...</td>\n",
       "      <td>bananas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date             Round                  Category  Value  \\\n",
       "0         3965 2001-11-23         Jeopardy!         FILMS OF THE '70s  100.0   \n",
       "1         3279 1998-12-03         Jeopardy!       FABULOUS BAKER BOYS  400.0   \n",
       "2         1871 1992-10-26  Double Jeopardy!                OLD MOVIES  400.0   \n",
       "3         3077 1998-01-06  Double Jeopardy!  COLORFUL WORDS & PHRASES  600.0   \n",
       "4         4720 2005-02-25         Jeopardy!       FRUITS & VEGETABLES  800.0   \n",
       "\n",
       "                                            Question            Answer  \n",
       "0  Cleavon Little plays Black Bart, the sheriff o...   Blazing Saddles  \n",
       "1                    Trumpet-playing Baker seen here        Chet Baker  \n",
       "2  Charley Grapewin who played Grandpa Joad in \"T...  The Wizard of Oz  \n",
       "3  This colorful Jimi Hendrix classic \"experience...     \"Purple Haze\"  \n",
       "4  It's the leading agricultural product of the i...           bananas  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the dumb spaces\n",
    "df.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']\n",
    "\n",
    "# Convert to Datetime\n",
    "df['Air Date'] = pd.to_datetime(df['Air Date'])\n",
    "\n",
    "# Clean out Value column\n",
    "df['Value'] = df['Value'].str.replace('$','')\n",
    "df['Value'] = df['Value'].str.replace(',','')\n",
    "df['Value'] = df['Value'].apply(lambda x: None if x == 'None' else int(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[video clue]                                                 3\n",
       "Charlie Parker                                               2\n",
       "May 29, 1917 in Brookline, Massachusetts                     2\n",
       "This language spoken in Reykjavik is also called Islenska    2\n",
       "Bjork                                                        2\n",
       "Name: Question, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Question'].value_counts()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21693, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop some useless questions\n",
    "df = df[df['Question'] != '[audio clue]']\n",
    "df = df[df['Question'] != '[video clue]']\n",
    "df = df[df['Question'] != '[filler]']\n",
    "df = df[df['Question'] != '(audio clue)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21689, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your']\n"
     ]
    }
   ],
   "source": [
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print len(stopwords)\n",
    "print stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions = df['Question'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#not super pythonic, no, not at all.\n",
    "#use extend so it's a big flat list of vocab\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in questions:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cleavon</th>\n",
       "      <td>cleavon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>littl</th>\n",
       "      <td>little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>plays</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>bart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words\n",
       "cleavon  cleavon\n",
       "littl     little\n",
       "play       plays\n",
       "black      black\n",
       "bart        bart"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_test.pkl', 'tfidf_test.pkl_01.npy', 'tfidf_test.pkl_02.npy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "#                                  min_df=0.2, stop_words='english',\n",
    "#                                  use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                                 tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "# %time tfidf_matrix = tfidf_vectorizer.fit_transform(questions)\n",
    "\n",
    "tfidf_vectorizer.fit(questions)\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_test.pkl')\n",
    "\n",
    "# print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = joblib.load('tfidf_test.pkl')\n",
    "tfidf_matrix = tfidf_vectorizer.transform(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 48s, sys: 8.88 s, total: 2min 57s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 50\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21689"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3965</td>\n",
       "      <td>2001-11-23</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FILMS OF THE '70s</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Cleavon Little plays Black Bart, the sheriff o...</td>\n",
       "      <td>Blazing Saddles</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3279</td>\n",
       "      <td>1998-12-03</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FABULOUS BAKER BOYS</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Trumpet-playing Baker seen here</td>\n",
       "      <td>Chet Baker</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1871</td>\n",
       "      <td>1992-10-26</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>OLD MOVIES</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Charley Grapewin who played Grandpa Joad in \"T...</td>\n",
       "      <td>The Wizard of Oz</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3077</td>\n",
       "      <td>1998-01-06</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>COLORFUL WORDS &amp; PHRASES</td>\n",
       "      <td>600.0</td>\n",
       "      <td>This colorful Jimi Hendrix classic \"experience...</td>\n",
       "      <td>\"Purple Haze\"</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4720</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>FRUITS &amp; VEGETABLES</td>\n",
       "      <td>800.0</td>\n",
       "      <td>It's the leading agricultural product of the i...</td>\n",
       "      <td>bananas</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date             Round                  Category  Value  \\\n",
       "0         3965 2001-11-23         Jeopardy!         FILMS OF THE '70s  100.0   \n",
       "1         3279 1998-12-03         Jeopardy!       FABULOUS BAKER BOYS  400.0   \n",
       "2         1871 1992-10-26  Double Jeopardy!                OLD MOVIES  400.0   \n",
       "3         3077 1998-01-06  Double Jeopardy!  COLORFUL WORDS & PHRASES  600.0   \n",
       "4         4720 2005-02-25         Jeopardy!       FRUITS & VEGETABLES  800.0   \n",
       "\n",
       "                                            Question            Answer  \\\n",
       "0  Cleavon Little plays Black Bart, the sheriff o...   Blazing Saddles   \n",
       "1                    Trumpet-playing Baker seen here        Chet Baker   \n",
       "2  Charley Grapewin who played Grandpa Joad in \"T...  The Wizard of Oz   \n",
       "3  This colorful Jimi Hendrix classic \"experience...     \"Purple Haze\"   \n",
       "4  It's the leading agricultural product of the i...           bananas   \n",
       "\n",
       "   Cluster  \n",
       "0       21  \n",
       "1       32  \n",
       "2       21  \n",
       "3       32  \n",
       "4       22  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32    6329\n",
       "36    1833\n",
       "0     1197\n",
       "7      564\n",
       "21     536\n",
       "1      477\n",
       "2      433\n",
       "12     431\n",
       "10     420\n",
       "16     417\n",
       "45     386\n",
       "18     383\n",
       "30     347\n",
       "27     344\n",
       "38     344\n",
       "22     341\n",
       "49     332\n",
       "35     315\n",
       "6      311\n",
       "39     296\n",
       "20     271\n",
       "44     258\n",
       "42     258\n",
       "46     256\n",
       "41     244\n",
       "9      241\n",
       "4      240\n",
       "8      240\n",
       "31     236\n",
       "28     233\n",
       "47     225\n",
       "33     220\n",
       "26     220\n",
       "11     211\n",
       "19     211\n",
       "3      211\n",
       "14     204\n",
       "23     202\n",
       "5      200\n",
       "43     163\n",
       "25     137\n",
       "29     131\n",
       "48     120\n",
       "37     119\n",
       "40     118\n",
       "17     109\n",
       "24     106\n",
       "13      98\n",
       "15      88\n",
       "34      83\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: games, originally, created, gods, host, produced,\n",
      "\n",
      "Cluster 0 categories: F, I, L, M, S,  , O, F,  , T, H, E,  , ', 7, 0, s,\n",
      "\n",
      "Cluster 1 words: including, work, authors, 's, authors, novel,\n",
      "\n",
      "Cluster 1 categories: F, A, B, U, L, O, U, S,  , B, A, K, E, R,  , B, O, Y, S,\n",
      "\n",
      "Cluster 2 words: became, house, white, marry, march, daughter,\n",
      "\n",
      "Cluster 2 categories: O, L, D,  , M, O, V, I, E, S,\n",
      "\n",
      "Cluster 3 words: song, general, hit, 's, hit, sings,\n",
      "\n",
      "Cluster 3 categories: C, O, L, O, R, F, U, L,  , W, O, R, D, S,  , &,  , P, H, R, A, S, E, S,\n",
      "\n",
      "Cluster 4 words: world, world, 's, world, war, world,\n",
      "\n",
      "Cluster 4 categories: F, R, U, I, T, S,  , &,  , V, E, G, E, T, A, B, L, E, S,\n",
      "\n",
      "Cluster 5 words: mark, middle, real, twain, 's, mark,\n",
      "\n",
      "Cluster 5 categories: S, H, O, R, T,  , S, T, O, R, I, E, S,\n",
      "\n",
      "Cluster 6 words: like, sound, sound, 's, type, 's,\n",
      "\n",
      "Cluster 6 categories: P, R, E, S, I, D, E, N, T, S,  , &,  , B, A, S, E, B, A, L, L,\n",
      "\n",
      "Cluster 7 words: href=, http, href=, /a, target=, target=,\n",
      "\n",
      "Cluster 7 categories: W, O, M, E, N,  , S, A, I, N, T, S,\n",
      "\n",
      "Cluster 8 words: life, live, man, 's, man, want,\n",
      "\n",
      "Cluster 8 categories: W, I, N, T, E, R,  , S, P, O, R, T, S,  , R, E, V, I, E, W,\n",
      "\n",
      "Cluster 9 words: means, verb, adjective, adjective, verb, 's,\n",
      "\n",
      "Cluster 9 categories: C, A, R, S,\n",
      "\n",
      "Cluster 10 words: used, type, 's, used, make, 's,\n",
      "\n",
      "Cluster 10 categories: M, A, T, E, R, I, A, L, S,\n",
      "\n",
      "Cluster 11 words: did, john, did, n't, did, n't,\n",
      "\n",
      "Cluster 11 categories: T, H, E, A, T, R, E,  , C, R, O, S, S, W, O, R, D,  , C, L, U, E, S,  , \", M, \",\n",
      "\n",
      "Cluster 12 words: n't, before, ca, ca, does, does,\n",
      "\n",
      "Cluster 12 categories: D, A, T, E,  , N, I, G, H, T,\n",
      "\n",
      "Cluster 13 words: mother, emmy, 's, 's, won, won,\n",
      "\n",
      "Cluster 13 categories: B, R, I, T, I, S, H,  , H, I, S, T, O, R, Y,\n",
      "\n",
      "Cluster 14 words: time, 's, 's, magazine, time, good,\n",
      "\n",
      "Cluster 14 categories: D, O, N, ', T,  , B, E,  , S, U, C, H,  , A,  , H, E, D, G, E, H, O, G,\n",
      "\n",
      "Cluster 15 words: version, games, 's, 's, film, version,\n",
      "\n",
      "Cluster 15 categories: W, H, E, R, E,  , A, R, E,  , W, E, ?,\n",
      "\n",
      "Cluster 16 words: city, city, 's, home, museum, largest,\n",
      "\n",
      "Cluster 16 categories: U, ., S, .,  , P, O, R, T,  , C, I, T, I, E, S,\n",
      "\n",
      "Cluster 17 words: country, country, 's, country, country, island,\n",
      "\n",
      "Cluster 17 categories: W, H, A, T, ', S,  , U, P, ,,  , D, U, C, K, ?,\n",
      "\n",
      "Cluster 18 words: state, 's, state, u.s., 's, u.s.,\n",
      "\n",
      "Cluster 18 categories: H, E, A, V, Y,  , M, E, T, A, L, L, U, R, G, Y,\n",
      "\n",
      "Cluster 19 words: king, 's, king, son, succeeded, 's,\n",
      "\n",
      "Cluster 19 categories: T, V,  , C, I, T, Y,  , S, E, T, T, I, N, G, S,\n",
      "\n",
      "Cluster 20 words: capital, 's, city, 's, capital, state,\n",
      "\n",
      "Cluster 20 categories: T, H, E,  , B, I, G,  , B, A, N, G, L, A, D, E, S, H,\n",
      "\n",
      "Cluster 21 words: plays, film, 's, tv, games, 's,\n",
      "\n",
      "Cluster 21 categories: A, T,  , T, H, E,  , P, H, A, R, M, A, C, Y,\n",
      "\n",
      "Cluster 22 words: island, french, language, 's, nation, official,\n",
      "\n",
      "Cluster 22 categories: I, N, D, E, P, E, N, D, E, N, C, E, !,\n",
      "\n",
      "Cluster 23 words: seen, seen, seen, _blank, target=, /a,\n",
      "\n",
      "Cluster 23 categories: \", I, \",  , P, O, D,\n",
      "\n",
      "Cluster 24 words: best, best, best, oscar, 's, picture,\n",
      "\n",
      "Cluster 24 categories: C, H, I, N, A,  , &,  , I, N, D, I, A,\n",
      "\n",
      "Cluster 25 words: bodies, bodies, water, 's, 's, heaven,\n",
      "\n",
      "Cluster 25 categories: E, U, R, O, P, E, A, N,  , A, R, T,\n",
      "\n",
      "Cluster 26 words: river, 's, flow, river, border, river,\n",
      "\n",
      "Cluster 26 categories: T, H, E,  , Y, E, A, R,  , O, F,  , T, H, E,  , H, E, A, D, L, I, N, E,\n",
      "\n",
      "Cluster 27 words: company, years, company, 's, years, ago,\n",
      "\n",
      "Cluster 27 categories: T, E, E, N, S,  , I, N,  , L, I, T, E, R, A, T, U, R, E,\n",
      "\n",
      "Cluster 28 words: wrote, 's, poet, book, novel, poem,\n",
      "\n",
      "Cluster 28 categories: F, U, R, N, I, T, U, R, E,\n",
      "\n",
      "Cluster 29 words: teams, baseball, baseball, 's, teams, sport,\n",
      "\n",
      "Cluster 29 categories: S, I, L, E, N, T,  , \", G, \",\n",
      "\n",
      "Cluster 30 words: word, means, word, comes, 's, 's,\n",
      "\n",
      "Cluster 30 categories: C, R, O, S, S, W, O, R, D,  , C, L, U, E, S,  , \", L, \",\n",
      "\n",
      "Cluster 31 words: clue, clue, crew, /a, href=, http,\n",
      "\n",
      "Cluster 31 categories: E, C, O, N, O, M, I, S, T,  , D, A, N, C, E,  , P, A, R, T, Y,\n",
      "\n",
      "Cluster 32 words: type, known, seen, u.s., make, group,\n",
      "\n",
      "Cluster 32 categories: R, E, S, C, U, E,  , M, E, !,\n",
      "\n",
      "Cluster 33 words: presidents, vice, vice, u.s., u.s., presidents,\n",
      "\n",
      "Cluster 33 categories: N, A, T, I, O, N, A, L, I, T, Y, ,,  , P, L, E, A, S, E,\n",
      "\n",
      "Cluster 34 words: only, 's, 's, only, bible, state,\n",
      "\n",
      "Cluster 34 categories: H, A, R, L, E, Q, U, I, N,  , &,  , C, O, L, U, M, B, I, N, E,\n",
      "\n",
      "Cluster 35 words: film, starred, 's, based, film, directed,\n",
      "\n",
      "Cluster 35 categories: T, H, E,  , V, I, R, G, I, N, I, A, N,\n",
      "\n",
      "Cluster 36 words: 's, seen, tv, type, known, book,\n",
      "\n",
      "Cluster 36 categories: F, I, R, S, T,  , A, I, D,\n",
      "\n",
      "Cluster 37 words: number, 's, 's, total, total, atomic,\n",
      "\n",
      "Cluster 37 categories: E, D,  , T, V,\n",
      "\n",
      "Cluster 38 words: american, sea, south, south, north, 's,\n",
      "\n",
      "Cluster 38 categories: P, O, P,  , M, U, S, I, C,  , R, H, Y, M, E,  , T, I, M, E,\n",
      "\n",
      "Cluster 39 words: woman, court, school, supreme, texas, supreme,\n",
      "\n",
      "Cluster 39 categories: A, M, E, R, I, C, A, N,  , G, O, V, E, R, N, M, E, N, T,\n",
      "\n",
      "Cluster 40 words: york, new, new, new, york, city,\n",
      "\n",
      "Cluster 40 categories: U, ., S, .,  , P, R, E, S, I, D, E, N, T, S,\n",
      "\n",
      "Cluster 41 words: people, caused, common, disease, 's, people,\n",
      "\n",
      "Cluster 41 categories: R, E, L, I, G, I, O, N,\n",
      "\n",
      "Cluster 42 words: term, 2-word, 2-word, 's, coined, 's,\n",
      "\n",
      "Cluster 42 categories: I, N,  , T, H, E,  , D, I, C, T, I, O, N, A, R, Y,\n",
      "\n",
      "Cluster 43 words: areas, union, statue, square, nyc, 's,\n",
      "\n",
      "Cluster 43 categories: M, A, R, T, I, N,  , L, U, T, H, E, R,  , K, I, N, G,\n",
      "\n",
      "Cluster 44 words: man, 's, man, planned, became, famous,\n",
      "\n",
      "Cluster 44 categories: C, R, O, S, S, W, O, R, D,  , C, L, U, E, S,  , \", K, \",\n",
      "\n",
      "Cluster 45 words: country, 's, africa, independence, central, african,\n",
      "\n",
      "Cluster 45 categories: O, R, G, A, N, I, Z, A, T, I, O, N, S,  , F, O, R,  , S, H, O, R, T,\n",
      "\n",
      "Cluster 46 words: day, 's, 's, celebration, years, holiday,\n",
      "\n",
      "Cluster 46 categories: W, H, E, R, E, ', S,  , T, H, E,  , F, I, R, E, ?,\n",
      "\n",
      "Cluster 47 words: saying, 's, saying, n't, love, man,\n",
      "\n",
      "Cluster 47 categories: I, N,  , T, H, E,  , D, I, C, T, I, O, N, A, R, Y,\n",
      "\n",
      "Cluster 48 words: head, 's, 's, shaving, head, welsh,\n",
      "\n",
      "Cluster 48 categories: M, U, S, I, C, A, L,  , I, N, S, T, R, U, M, E, N, T, S,\n",
      "\n",
      "Cluster 49 words: title, title, character, 's, novel, 's,\n",
      "\n",
      "Cluster 49 categories: G, E, O, G, R, A, P, H, I, C,  , \", S, A, I, N, T, \", s,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    for ind in order_centroids[i, :6]:\n",
    "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Cluster %d categories:\" % i, end='')\n",
    "    for cat in df.ix[i]['Category']:#.values.tolist():\n",
    "        print(' %s,' % cat, end='')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
