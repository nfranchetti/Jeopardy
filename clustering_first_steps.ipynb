{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216930, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.read_csv('data/JEOPARDY_CSV.csv', encoding='utf-8')\n",
    "print full_df.shape\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = full_df.sample(frac=0.1)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6098</td>\n",
       "      <td>2011-03-02</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ART -ISMS</td>\n",
       "      <td>$800</td>\n",
       "      <td>Abstract expressionism has been called the fir...</td>\n",
       "      <td>the United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3690</td>\n",
       "      <td>2000-09-22</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>\"PH\"OOEY!</td>\n",
       "      <td>$400</td>\n",
       "      <td>Fashionable critter seen here</td>\n",
       "      <td>Pheasant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2910</td>\n",
       "      <td>1997-04-04</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>MEDICINE</td>\n",
       "      <td>$1000</td>\n",
       "      <td>Streptococci cause this childhood \"fever\" char...</td>\n",
       "      <td>Scarlet fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3928</td>\n",
       "      <td>2001-10-03</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>SECOND-LARGEST CITIES</td>\n",
       "      <td>$400</td>\n",
       "      <td>In Spain, it's second to Madrid</td>\n",
       "      <td>Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5836</td>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>SIDEKICKS</td>\n",
       "      <td>$600</td>\n",
       "      <td>Smee, a sidekick of this handicaptain, had a c...</td>\n",
       "      <td>Captain Hook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date             Round               Category  Value  \\\n",
       "0         6098  2011-03-02  Double Jeopardy!              ART -ISMS   $800   \n",
       "1         3690  2000-09-22         Jeopardy!              \"PH\"OOEY!   $400   \n",
       "2         2910  1997-04-04  Double Jeopardy!               MEDICINE  $1000   \n",
       "3         3928  2001-10-03         Jeopardy!  SECOND-LARGEST CITIES   $400   \n",
       "4         5836  2010-01-18         Jeopardy!              SIDEKICKS   $600   \n",
       "\n",
       "                                            Question             Answer  \n",
       "0  Abstract expressionism has been called the fir...  the United States  \n",
       "1                      Fashionable critter seen here           Pheasant  \n",
       "2  Streptococci cause this childhood \"fever\" char...      Scarlet fever  \n",
       "3                    In Spain, it's second to Madrid          Barcelona  \n",
       "4  Smee, a sidekick of this handicaptain, had a c...       Captain Hook  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6098</td>\n",
       "      <td>2011-03-02</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>ART -ISMS</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Abstract expressionism has been called the fir...</td>\n",
       "      <td>the United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3690</td>\n",
       "      <td>2000-09-22</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>\"PH\"OOEY!</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Fashionable critter seen here</td>\n",
       "      <td>Pheasant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2910</td>\n",
       "      <td>1997-04-04</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>MEDICINE</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Streptococci cause this childhood \"fever\" char...</td>\n",
       "      <td>Scarlet fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3928</td>\n",
       "      <td>2001-10-03</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>SECOND-LARGEST CITIES</td>\n",
       "      <td>400.0</td>\n",
       "      <td>In Spain, it's second to Madrid</td>\n",
       "      <td>Barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5836</td>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>SIDEKICKS</td>\n",
       "      <td>600.0</td>\n",
       "      <td>Smee, a sidekick of this handicaptain, had a c...</td>\n",
       "      <td>Captain Hook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date             Round               Category   Value  \\\n",
       "0         6098 2011-03-02  Double Jeopardy!              ART -ISMS   800.0   \n",
       "1         3690 2000-09-22         Jeopardy!              \"PH\"OOEY!   400.0   \n",
       "2         2910 1997-04-04  Double Jeopardy!               MEDICINE  1000.0   \n",
       "3         3928 2001-10-03         Jeopardy!  SECOND-LARGEST CITIES   400.0   \n",
       "4         5836 2010-01-18         Jeopardy!              SIDEKICKS   600.0   \n",
       "\n",
       "                                            Question             Answer  \n",
       "0  Abstract expressionism has been called the fir...  the United States  \n",
       "1                      Fashionable critter seen here           Pheasant  \n",
       "2  Streptococci cause this childhood \"fever\" char...      Scarlet fever  \n",
       "3                    In Spain, it's second to Madrid          Barcelona  \n",
       "4  Smee, a sidekick of this handicaptain, had a c...       Captain Hook  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the dumb spaces\n",
    "df.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']\n",
    "\n",
    "# Convert to Datetime\n",
    "df['Air Date'] = pd.to_datetime(df['Air Date'])\n",
    "\n",
    "# Clean out Value column\n",
    "df['Value'] = df['Value'].str.replace('$','')\n",
    "df['Value'] = df['Value'].str.replace(',','')\n",
    "df['Value'] = df['Value'].apply(lambda x: None if x == 'None' else int(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your']\n"
     ]
    }
   ],
   "source": [
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print len(stopwords)\n",
    "print stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions = df['Question'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#not super pythonic, no, not at all.\n",
    "#use extend so it's a big flat list of vocab\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in questions:\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 40 ms, total: 1.19 s\n",
      "Wall time: 1.14 s\n",
      "(2169, 34278)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "#                                  min_df=0.2, stop_words='english',\n",
    "#                                  use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                                 tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(questions)\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.37 s, sys: 16 ms, total: 2.38 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 20\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2169"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5505</td>\n",
       "      <td>2008-07-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>YOUR STATE IS PARKED</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>Cherokee Landing State Park</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4515</td>\n",
       "      <td>2004-04-02</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>PICTURE ME!</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>He's been called the final victim of the reign...</td>\n",
       "      <td>Robespierre</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5445</td>\n",
       "      <td>2008-04-18</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>LAMPLIGHTERS</td>\n",
       "      <td>600.0</td>\n",
       "      <td>In the evenings she carried a lamp while walki...</td>\n",
       "      <td>Florence Nightingale</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5515</td>\n",
       "      <td>2008-07-25</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE NEW YORK TIMES 2008 NEWS</td>\n",
       "      <td>800.0</td>\n",
       "      <td>A tentative deal with producers reported on Fe...</td>\n",
       "      <td>the Writers Guild strike</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4103</td>\n",
       "      <td>2002-06-05</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>THERE OUGHTA BE A LAW</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Consumers use chapter 7 or 13 of this code, a ...</td>\n",
       "      <td>bankruptcy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date             Round                      Category  \\\n",
       "0         5505 2008-07-11  Double Jeopardy!          YOUR STATE IS PARKED   \n",
       "1         4515 2004-04-02  Double Jeopardy!                   PICTURE ME!   \n",
       "2         5445 2008-04-18         Jeopardy!                  LAMPLIGHTERS   \n",
       "3         5515 2008-07-25         Jeopardy!  THE NEW YORK TIMES 2008 NEWS   \n",
       "4         4103 2002-06-05  Double Jeopardy!         THERE OUGHTA BE A LAW   \n",
       "\n",
       "    Value                                           Question  \\\n",
       "0  2500.0                        Cherokee Landing State Park   \n",
       "1  1600.0  He's been called the final victim of the reign...   \n",
       "2   600.0  In the evenings she carried a lamp while walki...   \n",
       "3   800.0  A tentative deal with producers reported on Fe...   \n",
       "4   400.0  Consumers use chapter 7 or 13 of this code, a ...   \n",
       "\n",
       "                     Answer  Cluster  \n",
       "0                  Oklahoma        7  \n",
       "1               Robespierre        3  \n",
       "2      Florence Nightingale        3  \n",
       "3  the Writers Guild strike        1  \n",
       "4                bankruptcy        1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     852\n",
       "3     253\n",
       "6     113\n",
       "7     111\n",
       "10     74\n",
       "17     72\n",
       "15     68\n",
       "8      68\n",
       "19     67\n",
       "11     61\n",
       "12     56\n",
       "2      51\n",
       "18     50\n",
       "16     48\n",
       "4      46\n",
       "14     43\n",
       "9      43\n",
       "5      37\n",
       "0      29\n",
       "13     27\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: people, sequel, saved, willie, bruce, speaking,\n",
      "\n",
      "Cluster 0 categories: Y, O, U, R,  , S, T, A, T, E,  , I, S,  , P, A, R, K, E, D,\n",
      "\n",
      "Cluster 1 words: use, type, years, films, century, like,\n",
      "\n",
      "Cluster 1 categories: P, I, C, T, U, R, E,  , M, E, !,\n",
      "\n",
      "Cluster 2 words: target=, _blank, href=, http, href=, /a,\n",
      "\n",
      "Cluster 2 categories: L, A, M, P, L, I, G, H, T, E, R, S,\n",
      "\n",
      "Cluster 3 words: 's, city, state, home, seen, type,\n",
      "\n",
      "Cluster 3 categories: T, H, E,  , N, E, W,  , Y, O, R, K,  , T, I, M, E, S,  , 2, 0, 0, 8,  , N, E, W, S,\n",
      "\n",
      "Cluster 4 words: once, chief, die, arizona, territory, napoleon,\n",
      "\n",
      "Cluster 4 categories: T, H, E, R, E,  , O, U, G, H, T, A,  , B, E,  , A,  , L, A, W,\n",
      "\n",
      "Cluster 5 words: river, north, continent, lake, flows, river,\n",
      "\n",
      "Cluster 5 categories: B, R, O, A, D, W, A, Y,  , D, E, B, U, T, S,\n",
      "\n",
      "Cluster 6 words: countries, n't, american, south, 's, countries,\n",
      "\n",
      "Cluster 6 categories: L, E, T, ', S,  , S, P, E, A, K,  , I, T, A, L, I, A, N,\n",
      "\n",
      "Cluster 7 words: play, new, new, york, 's, killed,\n",
      "\n",
      "Cluster 7 categories: L, E, G, E, N, D, A, R, Y,  , C, R, E, A, T, U, R, E, S,\n",
      "\n",
      "Cluster 8 words: http, href=, href=, /a, target=, target=,\n",
      "\n",
      "Cluster 8 categories: A, C, A, D, E, M, Y,  , A, W, A, R, D, -, W, I, N, N, I, N, G,  , A, C, T, O, R, S,\n",
      "\n",
      "Cluster 9 words: coming, included, strange, particles, 's, elements,\n",
      "\n",
      "Cluster 9 categories: 1, 9, t, h,  , C, E, N, T, U, R, Y,  , L, I, T, E, R, A, R, Y,  , Q, U, O, T, E, S,\n",
      "\n",
      "Cluster 10 words: book, old, character, say, title, title,\n",
      "\n",
      "Cluster 10 categories: H, O, M, O, P, H, O, N, E, S,\n",
      "\n",
      "Cluster 11 words: works, painted, written, desert, consists, movement,\n",
      "\n",
      "Cluster 11 categories: T, E, L, L,  , M, E,  , \", Y, \",\n",
      "\n",
      "Cluster 12 words: islands, great, point, middle, 's, eastern,\n",
      "\n",
      "Cluster 12 categories: J, O, H, N,  , B, R, O, W, N,\n",
      "\n",
      "Cluster 13 words: player, baseball, hall, fame, hall, induction,\n",
      "\n",
      "Cluster 13 categories: M, A, K, I, N, G,  , W, A, V, E, S,\n",
      "\n",
      "Cluster 14 words: song, singer, pass, lady, away, hit,\n",
      "\n",
      "Cluster 14 categories: E, N, T, E, R, T, A, I, N, I, N, G,  , C, R, I, T, T, E, R, S,\n",
      "\n",
      "Cluster 15 words: presided, became, only, vice, 's, 's,\n",
      "\n",
      "Cluster 15 categories: B, E, F, O, R, E,  , &,  , A, F, T, E, R,\n",
      "\n",
      "Cluster 16 words: born, british, april, 's, prime, capital,\n",
      "\n",
      "Cluster 16 categories: G, E, T,  , T, O,  , W, O, R, K,\n",
      "\n",
      "Cluster 17 words: makes, goods, world, feet, largest, 's,\n",
      "\n",
      "Cluster 17 categories: P, E, N,  , N, A, M, E, S,\n",
      "\n",
      "Cluster 18 words: short, story, created, writer, novelist, county,\n",
      "\n",
      "Cluster 18 categories: H, O, T,  , \", R, O, D, \", s,\n",
      "\n",
      "Cluster 19 words: means, word, greek, know, derived, 's,\n",
      "\n",
      "Cluster 19 categories: G, R, E, A, T,  , T, H, I, N, K, E, R, S,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    for ind in order_centroids[i, :6]:\n",
    "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Cluster %d categories:\" % i, end='')\n",
    "    for cat in df.ix[i]['Category']:#.values.tolist():\n",
    "        print(' %s,' % cat, end='')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
